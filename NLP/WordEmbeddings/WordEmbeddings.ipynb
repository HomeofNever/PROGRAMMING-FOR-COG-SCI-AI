{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "v2goQ7zZ6Jky"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9iAu-fZNjm0H"
   },
   "source": [
    "## Word Embeddings\n",
    "\n",
    "* Define the semantics of words by the context in which they are used.\n",
    "* **word embeddings** are low-dimensional floating point vectors that are learned from data. \n",
    "* They are typically 256-dimensional, 512-dimensional, or 1024-dimensional when dealing with very large vocabularies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSr4VxTTjm0H"
   },
   "source": [
    "#### Two types of word embeddings:\n",
    "\n",
    "* **pre-trained word embeddings** are pre-computed embeddings that are learned from a large corpus.\n",
    "    - You can load these into your model and then fine-tune for your domain.\n",
    "    - The two most used are Word2Vec and GloVe\n",
    "* **Learned word embeddings** are vectors that are learned jointly with the other model parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpXyXho8jm0H"
   },
   "source": [
    "## Pre-trained word embeddings\n",
    "\n",
    "* Sometimes you have so little training data available that could never use your data alone to learn an appropriate task-specific embedding of your vocabulary. \n",
    "\n",
    "* In this case, instead of learning word embeddings you use embedding vectors from a pre-computed \n",
    "embedding space that captures generic aspects of language structure. \n",
    "\n",
    "* These pre-computed embeddings are generally computed using word occurrence statistics.\n",
    "* Word2Vec and GloVe are the two most common pre-trained word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2aXkKxgbjm0H"
   },
   "source": [
    "## Word2Vec\n",
    "\n",
    "* First pre-trained word embedding system\n",
    "\n",
    "* Developed by a team led Thomas Mikolov at Google in 2013\n",
    "\n",
    "https://papers.nips.cc/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf\n",
    "\n",
    "* Two types of models to learn the embeddings\n",
    "    - Continuous Bag of Words (CBOW)\n",
    "    - Skip-Gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VAiXwEzZjm0H"
   },
   "source": [
    "#### Continuous Bag of Words (CBOW)\n",
    "\n",
    "* Maps Context to Target Word\n",
    "    - I went to the bank on Tuesday. Predict 'bank' from {I,went,to,the,on,Tuesday}\n",
    "\n",
    "![](CBOW.png)\n",
    "$$\\text{Figure 1. Word2Vec CBOW}$$\n",
    "\n",
    "* $x_{ik} i=1,2,....C$ where C = number of words in context, k = Number of words in vocabulary.\n",
    "    - Each $x_{ik}$ is a one-hot encoded vector of the context word\n",
    "* $W_{VxN}$ is the weight matrix mapping the word to the hidden layer\n",
    "* $h_i$ is hidden layer output. $h_i = \\frac{1}{C}W^T(x_1,...,x_C)$\n",
    "* $W^{'}_{NxV}$ is the weight matrix mapping the hidden layer to the Output layer\n",
    "    - The hidden layer has no non-linear activation\n",
    "* $y_j$ is the  V_dimension output distribution (i.e. the output activation is the softmax function)  for the target word.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtFcjG_Vjm0H"
   },
   "source": [
    "#### Skip-Gram Model\n",
    "\n",
    "* Maps Word to Context\n",
    "    - I went to the bank on Tuesday. Predict {I,went,to,the,on,Tuesday} from 'bank'\n",
    "\n",
    "![](Skip-Gram.png)\n",
    "$$\\text{Figure 2. Skip-Gram Model}$$\n",
    "\n",
    "* $x_k$ is the one-hot encoded word used to predict the context\n",
    "* $W_{VxN}$ is the weight matrix mapping the word to the hidden layer\n",
    "$h_i$ is hidden layer input.\n",
    "* $W^{'}_{NxV}$ is the weight matrix mapping the hidden layer to the Output layer\n",
    "* $y_{ij} i=1,2,....C$ is the V_dimension output distribution (i.e. the output activation is the softmax function)  for the i context word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8kSUsoO1Z3U"
   },
   "source": [
    "### Download the word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9WbgU0u66nw4",
    "outputId": "248c7458-1009-4eac-cf6e-d63fa2663637"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================================================-] 100.0% 1662.0/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "word2vec_model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EAnppTlU1foo"
   },
   "source": [
    "### Vector representation of a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5a3DLDARgOBS",
    "outputId": "eb23e8d7-5086-4c2a-c697-a9dff2cac4ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01831055,  0.05566406, -0.01153564,  0.07275391,  0.15136719,\n",
       "       -0.06176758,  0.20605469, -0.15332031, -0.05908203,  0.22851562,\n",
       "       -0.06445312, -0.22851562, -0.09472656, -0.03344727,  0.24707031,\n",
       "        0.05541992, -0.00921631,  0.1328125 , -0.15429688,  0.08105469,\n",
       "       -0.07373047,  0.24316406,  0.12353516, -0.09277344,  0.08203125,\n",
       "        0.06494141,  0.15722656,  0.11279297, -0.0612793 , -0.296875  ,\n",
       "       -0.13378906,  0.234375  ,  0.09765625,  0.17773438,  0.06689453,\n",
       "       -0.27539062,  0.06445312, -0.13867188, -0.08886719,  0.171875  ,\n",
       "        0.07861328, -0.10058594,  0.23925781,  0.03808594,  0.18652344,\n",
       "       -0.11279297,  0.22558594,  0.10986328, -0.11865234,  0.02026367,\n",
       "        0.11376953,  0.09570312,  0.29492188,  0.08251953, -0.05444336,\n",
       "       -0.0090332 , -0.0625    , -0.17578125, -0.08154297,  0.01062012,\n",
       "       -0.04736328, -0.08544922, -0.19042969, -0.30273438,  0.07617188,\n",
       "        0.125     , -0.05932617,  0.03833008, -0.03564453,  0.2421875 ,\n",
       "        0.36132812,  0.04760742,  0.00631714, -0.03088379, -0.13964844,\n",
       "        0.22558594, -0.06298828, -0.02636719,  0.1171875 ,  0.33398438,\n",
       "       -0.07666016, -0.06689453,  0.04150391, -0.15136719, -0.22460938,\n",
       "        0.03320312, -0.15332031,  0.07128906,  0.16992188,  0.11572266,\n",
       "       -0.13085938,  0.12451172, -0.20410156,  0.04736328, -0.296875  ,\n",
       "       -0.17480469,  0.00872803, -0.04638672,  0.10791016, -0.203125  ,\n",
       "       -0.27539062,  0.2734375 ,  0.02563477, -0.11035156,  0.0625    ,\n",
       "        0.1953125 ,  0.16015625, -0.13769531, -0.09863281, -0.1953125 ,\n",
       "       -0.22851562,  0.25390625,  0.00915527, -0.03857422,  0.3984375 ,\n",
       "       -0.1796875 ,  0.03833008, -0.24804688,  0.03515625,  0.03881836,\n",
       "        0.03442383, -0.04101562,  0.20214844, -0.03015137, -0.09619141,\n",
       "        0.11669922, -0.06738281,  0.0625    ,  0.10742188,  0.25585938,\n",
       "       -0.21777344,  0.05639648, -0.0065918 ,  0.16113281,  0.11865234,\n",
       "       -0.03088379, -0.11572266,  0.02685547,  0.03100586,  0.09863281,\n",
       "        0.05883789,  0.00634766,  0.11914062,  0.07324219, -0.01586914,\n",
       "        0.18457031,  0.05322266,  0.19824219, -0.22363281, -0.25195312,\n",
       "        0.15039062,  0.22753906,  0.05737305,  0.16992188, -0.22558594,\n",
       "        0.06494141,  0.11914062, -0.06640625, -0.10449219, -0.07226562,\n",
       "       -0.16992188,  0.0625    ,  0.14648438,  0.27148438, -0.02172852,\n",
       "       -0.12695312,  0.18457031, -0.27539062, -0.36523438, -0.03491211,\n",
       "       -0.18554688,  0.23828125, -0.13867188,  0.00296021,  0.04272461,\n",
       "        0.13867188,  0.12207031,  0.05957031, -0.22167969, -0.18945312,\n",
       "       -0.23242188, -0.28710938, -0.00866699, -0.16113281, -0.24316406,\n",
       "        0.05712891, -0.06982422,  0.00053406, -0.10302734, -0.13378906,\n",
       "       -0.16113281,  0.11621094,  0.31640625, -0.02697754, -0.01574707,\n",
       "        0.11425781, -0.04174805,  0.05908203,  0.02661133, -0.08642578,\n",
       "        0.140625  ,  0.09228516, -0.25195312, -0.31445312, -0.05688477,\n",
       "        0.01031494,  0.0234375 , -0.02331543, -0.08056641,  0.01269531,\n",
       "       -0.34179688,  0.17285156, -0.16015625,  0.07763672, -0.03088379,\n",
       "        0.11962891,  0.11767578,  0.20117188, -0.01940918,  0.02172852,\n",
       "        0.23046875,  0.28125   , -0.17675781,  0.02978516,  0.08740234,\n",
       "       -0.06176758,  0.00939941, -0.09277344, -0.203125  ,  0.13085938,\n",
       "       -0.13671875, -0.00500488, -0.04296875,  0.12988281,  0.3515625 ,\n",
       "        0.0402832 , -0.12988281, -0.03173828,  0.28515625,  0.18261719,\n",
       "        0.13867188, -0.16503906, -0.26171875, -0.04345703,  0.0100708 ,\n",
       "        0.08740234,  0.00421143, -0.1328125 , -0.17578125, -0.04321289,\n",
       "       -0.015625  ,  0.16894531,  0.25      ,  0.37109375,  0.19921875,\n",
       "       -0.36132812, -0.10302734, -0.20800781, -0.20117188, -0.01519775,\n",
       "       -0.12207031, -0.12011719, -0.07421875, -0.04345703,  0.14160156,\n",
       "        0.15527344, -0.03027344, -0.09326172, -0.04589844,  0.16796875,\n",
       "       -0.03027344,  0.09179688, -0.10058594,  0.20703125,  0.11376953,\n",
       "       -0.12402344,  0.04003906,  0.06933594, -0.34570312,  0.03881836,\n",
       "        0.16210938,  0.05761719, -0.12792969, -0.05810547,  0.03857422,\n",
       "       -0.11328125, -0.1953125 , -0.28125   , -0.13183594,  0.15722656,\n",
       "       -0.09765625,  0.09619141, -0.09960938, -0.00285339, -0.03637695,\n",
       "        0.15429688,  0.06152344, -0.34570312,  0.11083984,  0.03344727],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model[\"beautiful\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GOyEJKmRCa4t",
    "outputId": "bc23a77d-ca40-4615-9109-483b371e44cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model[\"beautiful\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9qfbMxS1qDa"
   },
   "source": [
    "### Word vectors and the meanings of words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zR3zzQUrfEXe",
    "outputId": "ca4d3fcc-b0b1-4306-9e7b-0c84c1a168c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boy', 0.8543272018432617),\n",
       " ('teenage_girl', 0.7927976250648499),\n",
       " ('woman', 0.7494640946388245),\n",
       " ('teenager', 0.717249870300293),\n",
       " ('schoolgirl', 0.7075953483581543),\n",
       " ('teenaged_girl', 0.6650916337966919),\n",
       " ('daughter', 0.6489864587783813),\n",
       " ('mother', 0.6478164196014404),\n",
       " ('toddler', 0.6473966836929321),\n",
       " ('girls', 0.6154742240905762)]"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.most_similar(\"girl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Go8rwIO1RXU"
   },
   "source": [
    "#### queen - girl + boy = king"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DVNmvmnyw-9h",
    "outputId": "54a37962-fcbf-4a4d-bf3a-73624546390a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('king', 0.7298422455787659)]"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.most_similar(positive=['boy', 'queen'], negative=['girl'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "66JOCW0qBNLM",
    "outputId": "83ccf4c7-759a-4e0e-cdde-d000799a7285"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('king', 0.6958590149879456)]"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.most_similar(positive=['man', 'queen'], negative=['woman'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-aoG-4pRBa-t",
    "outputId": "8ff80263-2fd6-4397-a54a-e3bfd9a6d134"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('prince', 0.7020792961120605)]"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.most_similar(positive=['boy', 'princess'], negative=['girl'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "R9Tn9a3zjISS",
    "outputId": "0e55341b-1dcc-40e4-c7b7-889798e4c4aa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocab = [\"boy\", \"girl\", \"man\", \"woman\", \"king\", \"queen\", \"banana\", \"apple\", \"mango\", \"fruit\", \"coconut\", \"orange\",\n",
    "         \"peas\",\"carrots\",\"celery\",\"lettuce\",\"tomato\",\"whale\",\"elephant\"]\n",
    "\n",
    "def tsne_plot(model):\n",
    "    labels = []\n",
    "    wordvecs = []\n",
    "\n",
    "    for word in vocab:\n",
    "        wordvecs.append(model[word])\n",
    "        labels.append(word)\n",
    "    \n",
    "    tsne_model = TSNE(perplexity=3, n_components=2, init='pca', random_state=42) # projects to lower dimension\n",
    "    coordinates = tsne_model.fit_transform(wordvecs)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in coordinates:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "    plt.figure(figsize=(8,8)) \n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i],y[i])\n",
    "        plt.annotate(labels[i],\n",
    "                     xy=(x[i], y[i]),\n",
    "                     xytext=(2, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "    plt.show()\n",
    "\n",
    "tsne_plot(word2vec_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XNIXOVUijm0K"
   },
   "source": [
    "### Learned Word Embeddings: The Embedding layer\n",
    "\n",
    "* Learn the the geometric relationships between word vectors should reflect the semantic relationships between these words. \n",
    "* Word embeddings map language into a geometric space with a similarity metric.\n",
    "    - Words similar in meaning (e.g. cat and dog) should be close in the geometric space. \n",
    "    - The geometric distance (e.g. Euclidean distance) between any two word vectors should reflect the semantic distance of the associated words \n",
    "* The **embedding layer** represents a word as a vector in this geometric space learned through backpropagation.\n",
    "\n",
    "* The Embedding layer is like a dictionary mapping integer indices which represent specific words to real-valued  vectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bRf7uLyWjm0K"
   },
   "source": [
    "### Embedding layer in Tensorflow\n",
    "\n",
    "* The Embedding layer takes at least two arguments:\n",
    "    - The number of samples (i.e. words, tokens)\n",
    "    - The dimensionality (length) of the embedding vector\n",
    "\n",
    "* This layer returns a 3D floating point tensor, of shape (num_samples, sequence_length, embedding_dimensionality). \n",
    "\n",
    "* When this layer is instantiated, its weights are initially random. During training, these word vectors will be gradually adjusted via backpropagation, structuring the space into a representation that can be used in other layers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Hh_uE8lMjm0K",
    "outputId": "033beeb0-ff75-47db-c3a9-b4ad6f02b8ad"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten,Dense,Embedding\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFT3nljCjm0L"
   },
   "source": [
    "### Sentiment prediction using IMDB Movie Reviews\n",
    "\n",
    "* The number of words is restricted to the top 10,000 most common words in the reviews \n",
    "* The reviews are trucated to only 20 words. \n",
    "* The model will consist of:\n",
    "    - An 8-dimensional embedding for each of the 10,000 words\n",
    "    - Flatten layer the tensor to 2D, and \n",
    "    - A single Dense layer to classify a review as favorable or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J_NcpB55jm0L",
    "outputId": "1ad29280-8dc9-4825-e2eb-d824c52b2fbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n",
      "(25000,) (25000,) (25000,) (25000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features = 10000 # Number of words to consider as features\n",
    "\n",
    "maxlen = 20 # Cut text after maxlen (among top max_features most common words)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "type(X_train[0]),len(X_train[0]),max(X_train[0])\n",
    "\n",
    "X_train[0][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HzwwOFjnjm0L",
    "outputId": "85410e5d-e4b2-488c-ffaf-552e4dc9d7d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wr4e3kKfjm0L"
   },
   "source": [
    "#### Create 2D integer tensor of shape (samples, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eo2myv5Djm0L",
    "outputId": "ed386802-37f6-4e3e-c2e8-c714bb2f9df3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 20) (25000, 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  65,   16,   38, 1334,   88,   12,   16,  283,    5,   16, 4472,\n",
       "        113,  103,   32,   15,   16, 5345,   19,  178,   32], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
    "print(X_train.shape,X_test.shape)\n",
    "X_train[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2kHADgsUjm0L"
   },
   "source": [
    "#### Create Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "En54hcUsjm0L",
    "outputId": "ce8993b9-1338-435c-e09f-529e93ea340c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 20, 8)             80000     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 161       \n",
      "=================================================================\n",
      "Total params: 80,161\n",
      "Trainable params: 80,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(10000, 8, input_length=maxlen))\n",
    "# Output shape (samples, maxlen, 8)\n",
    "model.add(Flatten()) # Flatten into a 2D tensor of shape (samples, maxlen * 8)\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbuWTLQ-jm0L"
   },
   "source": [
    "#### Compile and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j05XO2Xdjm0L",
    "outputId": "e9664e78-a495-4224-fc8b-cd4f09409845"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6762 - acc: 0.6004 - val_loss: 0.6314 - val_acc: 0.6892\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.5505 - acc: 0.7459 - val_loss: 0.5306 - val_acc: 0.7276\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.4657 - acc: 0.7850 - val_loss: 0.4999 - val_acc: 0.7464\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.4272 - acc: 0.8043 - val_loss: 0.4933 - val_acc: 0.7504\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.4029 - acc: 0.8184 - val_loss: 0.4948 - val_acc: 0.7528\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.3838 - acc: 0.8288 - val_loss: 0.4980 - val_acc: 0.7554\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.3667 - acc: 0.8382 - val_loss: 0.4996 - val_acc: 0.7590\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.3497 - acc: 0.8483 - val_loss: 0.5036 - val_acc: 0.7568\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.3324 - acc: 0.8572 - val_loss: 0.5098 - val_acc: 0.7552\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.3149 - acc: 0.8676 - val_loss: 0.5165 - val_acc: 0.7588\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNQ80P7zjm0L"
   },
   "source": [
    "#### Compute classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "b3ekaY9Bjm0L"
   },
   "outputs": [],
   "source": [
    "def accuracy(x,y):\n",
    "    y_hat = model.predict(x)\n",
    "    foo = np.array([1 if i > .5 else 0 for i in y_hat[:,0] ])\n",
    "    return np.sum(foo == y)/len(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aFgB89_Bjm0L",
    "outputId": "cbf13ffd-093b-46f4-a62b-c35089cb1592"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.85516, 0.76136)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(X_train,y_train),accuracy(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_EaplDojm0L"
   },
   "source": [
    "* This model with a single Dense layer treats each word in the input sequence separately\n",
    "    - Inter-word relationships and structure sentence are not taken into account\n",
    "* We could add recurrent layers or 1D convolutional layers after the embedded sequences to learn features that take into account each sequence as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1SbCJ7r_jm0L"
   },
   "source": [
    "### Embedding layer Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "s9WIhzLajm0L",
    "outputId": "a941d8e5-79ac-465e-be23-54b30d048f2d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'1.7.0+cu101'"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2-549w4Ejm0L",
    "outputId": "f379fcf0-ec06-4b98-d5a8-b1c10a96d15b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6614,  0.2669,  0.0617,  0.6213, -0.4519]],\n",
      "       grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "word_to_ix = {\"hello\": 0, \"world\": 1}\n",
    "embeds = nn.Embedding(2, 5)  # 2 words in vocab, 5 dimensional embeddings\n",
    "lookup_tensor = torch.tensor([word_to_ix[\"hello\"]], dtype=torch.long)\n",
    "hello_embed = embeds(lookup_tensor)\n",
    "print(hello_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_tDJSfl7jm0L",
    "outputId": "cd6acc5e-9e9a-4652-c06f-721a51639d30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['When', 'forty'], 'winters'), (['forty', 'winters'], 'shall'), (['winters', 'shall'], 'besiege')]\n"
     ]
    }
   ],
   "source": [
    "CONTEXT_SIZE = 2\n",
    "EMBEDDING_DIM = 10\n",
    "# We will use Shakespeare Sonnet 2\n",
    "test_sentence = \"\"\"When forty winters shall besiege thy brow,\n",
    "And dig deep trenches in thy beauty's field,\n",
    "Thy youth's proud livery so gazed on now,\n",
    "Will be a totter'd weed of small worth held:\n",
    "Then being asked, where all thy beauty lies,\n",
    "Where all the treasure of thy lusty days;\n",
    "To say, within thine own deep sunken eyes,\n",
    "Were an all-eating shame, and thriftless praise.\n",
    "How much more praise deserv'd thy beauty's use,\n",
    "If thou couldst answer 'This fair child of mine\n",
    "Shall sum my count, and make my old excuse,'\n",
    "Proving his beauty by succession thine!\n",
    "This were to be new made when thou art old,\n",
    "And see thy blood warm when thou feel'st it cold.\"\"\".split()\n",
    "\n",
    "# Build a list of trigrams.  Each trigram is ([ word_i-2, word_i-1 ], target word)\n",
    "# Note: we should tokenize the input\n",
    "\n",
    "trigrams = [([test_sentence[i], test_sentence[i + 1]], test_sentence[i + 2])\n",
    "            for i in range(len(test_sentence) - 2)]\n",
    "\n",
    "print(trigrams[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "suMTkoI8jm0L",
    "outputId": "df940061-3d55-4859-84a4-a6426b5f5b71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = set(test_sentence)\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p1MRzaxgjm0L",
    "outputId": "dac85d4b-1b37-4f32-d8ca-ae12a4772d55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_ix[\"winters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LdIniu_Yjm0L",
    "outputId": "404b1cd3-61ce-483b-d2ce-0cbbf136ce6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NGramLanguageModeler(\n",
       "  (embeddings): Embedding(97, 10)\n",
       "  (linear1): Linear(in_features=20, out_features=128, bias=True)\n",
       "  (linear2): Linear(in_features=128, out_features=97, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NGramLanguageModeler(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1)) # Reshape\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs\n",
    "model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dHgmybaOjm0M"
   },
   "source": [
    "#### Negative Log-Likelihood Loss\n",
    "\n",
    "* Similar to cross-entropy loss.\n",
    "* In cross entropy loss (nn.CrossEntropyLoss) the forward function outputs logits which will be input to a softmax in the optimizer. \n",
    "* In negative log-likelihood loss (tensor.nn.NLLLoss) the log-softmax (tensor.LogSoftmax()) is called in the forward() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "BcwOY-H1jm0M"
   },
   "outputs": [],
   "source": [
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FmmOs1L5jm0M",
    "outputId": "d6c2e1bb-cb5a-4be9-b9f1-992776440dbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[521.18049717 518.48077965 515.80033612 513.13620043 510.48763585\n",
      " 507.85377598 505.23100877 502.62168455 500.02433562 497.43707323]\n"
     ]
    }
   ],
   "source": [
    "epochs =10\n",
    "losses = np.zeros(epochs)\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for context, target in trigrams:\n",
    "        \n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "\n",
    "        model.zero_grad()\n",
    "        log_probs = model(context_idxs) # forward pass\n",
    "\n",
    "        # Compute loss function with model output and target.\n",
    "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
    "        loss.backward() # compute gradients\n",
    "        optimizer.step() # update\n",
    "        \n",
    "        total_loss += loss.item() # accumulate loss\n",
    "    losses[epoch] = total_loss\n",
    "print(losses)  # The loss decreased every iteration over the training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_SOV7lgDjm0M",
    "outputId": "8af25cd6-dfac-4d40-f453-997b225fb5fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8336, -1.1937, -2.3073,  0.6030,  0.3151,  1.1425,  0.3057, -0.5796,\n",
       "          0.5641, -0.8775]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings(torch.tensor([word_to_ix[\"winters\"]], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uglZ_Mrtjm0M"
   },
   "source": [
    "### References\n",
    "\n",
    "Chollet, Francois (2018) Deep Learning with Python\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html\n",
    "\n",
    "https://arxiv.org/pdf/1411.2738.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "n9YzdMtXjm0M"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "WordEmbeddings.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
