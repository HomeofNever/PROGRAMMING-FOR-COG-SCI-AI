{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif,mutual_info_classif\n",
    "\n",
    "from sklearn.feature_selection import RFE,RFECV\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "* sklearn Feature Selection\n",
    "    - Univariate \n",
    "    - Recursive Elimination\n",
    "* Subset: Iterating over a learning method\n",
    "    - Best Subset\n",
    "    - Sequential        \n",
    "        - Forward\n",
    "        - Backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate feature selection in sklearn: SelectKbest\n",
    "\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html\n",
    "\n",
    "* Statistical test on a single variable (no relationship among variables)\n",
    "\n",
    "* Parameters\n",
    "    * k: number of features to select based on the scores determined by score_func\n",
    "    * score_func: Scoring function to evaluate features\n",
    "        - e.g. f_classif computes ANOVA F-statistic (classification only)\n",
    "\n",
    "* Transform method to select features from the feature array that is input (i.e. X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = pd.read_csv(\"wine.csv\")\n",
    "feats = wine.columns[0:-1]\n",
    "wine.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wine.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wine.iloc[:, 0:-1].values\n",
    "y =  LabelEncoder().fit_transform(wine.Customer_Segment) \n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_log_regress(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=0, \n",
    "                                                    stratify=y)\n",
    "\n",
    "    stdsc = StandardScaler()\n",
    "    X_train = stdsc.fit_transform(X_train)\n",
    "    X_test = stdsc.transform(X_test)\n",
    "    \n",
    "    model = LogisticRegression(random_state = 42)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_log_regress(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "SelBest = SelectKBest(score_func=f_classif, k=6) #f_classif computes ANOVA F-statistic\n",
    "SelBest.fit(X, y)\n",
    "\n",
    "# summarize scores\n",
    "np.set_printoptions(precision=3)\n",
    "print(\"The scores: \", SelBest.scores_)\n",
    "features = SelBest.transform(X)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print selected features\n",
    "idxs = SelBest.get_support()\n",
    "print(idxs)\n",
    "feats = wine.columns[0:-1]\n",
    "feats[idxs].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_log_regress(features,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html\n",
    "\n",
    "* User supplied estimator\n",
    "* Selects n features by recursively considering smaller and smaller sets of features\n",
    "    - defaults to selecting half the number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(model, n_features_to_select = 6)\n",
    "fit = rfe.fit(X, y)\n",
    "print(\"Num Features: \",fit.n_features_)\n",
    "print(\"Selected Features: \", wine.columns.values[:-1][fit.support_])\n",
    "print(\"Feature Ranking: \",fit.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "rfecv = RFECV(model,cv = 10,min_features_to_select = 6)\n",
    "fit = rfecv.fit(X, y)\n",
    "print(\"Num Features: \",fit.n_features_)\n",
    "print(\"Selected Features: \", wine.columns.values[:-1][fit.support_])\n",
    "print(\"Feature Ranking: \",fit.ranking_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset Selection \n",
    "\n",
    "* Models with different sets of features(predictors)\n",
    "\n",
    "* Best subset\n",
    "* Sequential\n",
    "    - Forward Selection\n",
    "    - Backwards\n",
    "    \n",
    "* No sklearn class for best subset or sequential methods. Code in this section is patterned after code by Sebastin Raschka.\n",
    "    \n",
    "* Model evaluation\n",
    "    - if splitting the data, the best performing model on the test set\n",
    "    - if using a single dataset (i.e. training data) use a metric that adjusts the error\n",
    "        - AIC, BIC or adjusted $R^2$\n",
    "\n",
    "    \n",
    "#### Best Subset\n",
    "\n",
    "* Exhaustive Search Algorithm  \n",
    "\n",
    "* Algorithm  \n",
    "    1. Let $M_0$ be the null model, which contains no predictors. It predicts the sample mean  \n",
    "    2. For k = 1,2...,p:  (p is the total number of predictors)\n",
    "        2.1 Fit all $\\binom{p}{k}$ models that contain exactly k predictors  \n",
    "        2.2 Pick the best and call it $M_k$ where best is  based on a scoring method \n",
    "    3. Select the single best from $M_0,...,M_p$ using some model evaluation criteria \n",
    "        \n",
    "* Best subset limited to small number of predictors (p)\n",
    "    - When p is large, larger search space implies a better chance of finding a model that looks good on the training data but with no predictive power on test data\n",
    "    - Overfitting and high variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential selection\n",
    "\n",
    "* Sequential feature selection algorithms are a family of greedy search algorithms\n",
    "    - used to reduce an initial d-dimensional feature space to a k-dimensional feature subspace where k < d\n",
    "    \n",
    "* Greedy algorithms make locally optimal choices at each stage of a combinatorial search problem and generally yield a suboptimal solution \n",
    "\n",
    "\n",
    "#### Forward selecton algorithm\n",
    "\n",
    "1. Let $M_0$ be the null model, which contains no predictors\n",
    "2. For k = 1,2...,p-1:  \n",
    "    2.1 Consider all p - k models that add one predictor to the ones in $M_k$  \n",
    "    2.2 Choose the best(based on scoring method) among these p - k models and call it $M_{k+1}$  \n",
    "3.  Select the single best from $M_1,...,M_p$ using some model evaluation criteria "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Better computationally than best subset\n",
    "* Not guaranteed to find the best model out of $2^n$ possible models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SFS():\n",
    "    def __init__(self, estimator, scoring=accuracy_score,test_size=0.25, random_state=1,show_details=False):\n",
    "        self.scoring = scoring\n",
    "        self.estimator = estimator\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "        self.show_details = show_details\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                            test_size=self.test_size,\n",
    "                                                            random_state=self.random_state)\n",
    "\n",
    "        num_features = X_train.shape[1]\n",
    "        self.Models = []\n",
    "        self.scores = []\n",
    "        indicies = list(range(num_features))\n",
    "        M = []\n",
    "        while indicies:\n",
    "            best_score = 0\n",
    "            best_model = None\n",
    "            for i in indicies:\n",
    "                m = M + [i]\n",
    "                score = self._calc_score(X_train, y_train, X_test, y_test, m)\n",
    "                if score > best_score:\n",
    "                   best_score = score\n",
    "                   best_model = i\n",
    "                #if self.show_details: print(m,round(score,3))\n",
    "            indicies.remove(best_model)\n",
    "            M = M + [best_model]\n",
    "            if self.show_details: print(\"Best score: \",round(best_score,3),\" Best model: \", M)\n",
    "            self.Models.append(M)\n",
    "            self.scores.append(best_score)\n",
    "        return self\n",
    "\n",
    "    def _calc_score(self, X_train, y_train, X_test, y_test, indices):\n",
    "        self.estimator.fit(X_train[:, indices], y_train)\n",
    "        y_pred = self.estimator.predict(X_test[:, indices])\n",
    "        score = self.scoring(y_test, y_pred)\n",
    "        return score\n",
    "    \n",
    "    def best_features(self,names):\n",
    "        return names[self.Models[np.argmax(self.scores)]].tolist()\n",
    "    \n",
    "    def transform(self,X):\n",
    "        return X[:,self.Models[np.argmax(self.scores)]]\n",
    "    \n",
    "    def plot(self):\n",
    "        # plotting performance of feature subsets\n",
    "        k_feat = [len(k) for k in sfs.Models]\n",
    "        plt.plot(k_feat, self.scores, marker='o')\n",
    "        plt.ylim([0.7, 1.02])\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Number of features')\n",
    "        plt.grid()\n",
    "        plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, \n",
    "                     stratify=y)\n",
    "\n",
    "stdsc = StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# selecting features\n",
    "sfs = SFS(knn,show_details=True)\n",
    "sfs.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sel = sfs.transform(X_train_std)\n",
    "X_train_sel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs.plot()\n",
    "\n",
    "sfs.best_features(wine.columns.values[:-1])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward selecton algorithm\n",
    "\n",
    "1. Let $M_0$ be the full model, which contains all the predictors\n",
    "2. For k = p,p-1,...,1:  \n",
    "    2.1 Consider all k models that contain all but one of the predictors in $M_k$ for a total of k - 1 predictors  \n",
    "    2.2 Choose the best(based on scoring method) among these k models and call it $M_{k-1}$  \n",
    "3.  Select the single best from $M_0,...,M_p$ using using some model evaluation criteria "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Like forward stepwise selection, the backward selection approach searches through only 1 + p(p + 1)/2 models\n",
    "    - Applicable when p is too large for best subset selection\n",
    "* Not guaranteed to yield the best model containing a subset of the p predictors.\n",
    "* Backward selection requires that the number of samples n is larger than the number of variables p (so that the full model can be fit).\n",
    "    - Forward stepwise can be used even when n < p, and so is the only viable subset method when p is very large.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SBS():\n",
    "    def __init__(self, estimator, scoring=accuracy_score,test_size=0.25, random_state=1,show_details=False):\n",
    "        self.scoring = scoring\n",
    "        self.estimator = estimator\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "        self.show_details = show_details\n",
    "        \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                            test_size=self.test_size,\n",
    "                                                            random_state=self.random_state)\n",
    "\n",
    "        num_features = X_train.shape[1]\n",
    "        indicies = tuple(range(num_features))\n",
    "        score = self._calc_score(X_train, y_train, X_test, y_test, indicies)\n",
    "        self.scores = [score]\n",
    "        self.Models = [indicies]\n",
    "        if self.show_details: print(\"Full Model score: \",score)\n",
    "        while num_features > 1:\n",
    "            best_model = None\n",
    "            best_score = 0 \n",
    "            #if self.show_details: print(\"Number of features: \",num_features)\n",
    "            for m in combinations(indicies, r = num_features - 1):\n",
    "                score = self._calc_score(X_train, y_train, X_test, y_test, m)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_model = m\n",
    "                #if self.show_details: print(m,round(score,3))\n",
    "            if self.show_details: print(\"Best score: \",round(best_score,3),\" Best model: \",best_model)\n",
    "            indicies = best_model\n",
    "            self.Models.append(best_model)\n",
    "            self.scores.append(best_score)\n",
    "            num_features -= 1\n",
    "        return self\n",
    "\n",
    "\n",
    "    def _calc_score(self, X_train, y_train, X_test, y_test, indices):\n",
    "        self.estimator.fit(X_train[:, indices], y_train)\n",
    "        y_pred = self.estimator.predict(X_test[:, indices])\n",
    "        score = self.scoring(y_test, y_pred)\n",
    "        return score\n",
    "    \n",
    "  \n",
    "\n",
    "    def plot(self):\n",
    "        # plotting performance of feature subsets\n",
    "        k_feat = [len(k) for k in self.Models]\n",
    "        plt.plot(k_feat, self.scores, marker='o')\n",
    "        plt.ylim([0.7, 1.02])\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Number of features')\n",
    "        plt.grid()\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# selecting features\n",
    "sbs = SBS(knn,show_details = True)\n",
    "sbs.fit(X_train_std, y_train)\n",
    "\n",
    "sbs.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k3 = list(sbs.Models[10]) # 3 features\n",
    "print(wine.columns[1:][k3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train_std, y_train)\n",
    "print('Training accuracy:', knn.score(X_train_std, y_train))\n",
    "print('Test accuracy:', knn.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train_std[:, k3], y_train)\n",
    "print('Training accuracy:', knn.score(X_train_std[:, k3], y_train))\n",
    "print('Test accuracy:', knn.score(X_test_std[:, k3], y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References\n",
    "\n",
    "Raschka,Sebastin & Mirjalili, Vahid (2017). Python Machine Learning, 2nd Edition, Packt Publishing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
