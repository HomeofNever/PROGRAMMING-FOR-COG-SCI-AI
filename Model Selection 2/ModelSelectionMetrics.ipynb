{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for choosing the best model from a set of models (for Linear Regression)\n",
    "\n",
    "* Want the model with the lowest test error but pure training error is a poor estimate of test error\n",
    "* Determine model with best generalization by **adjusting** training error\n",
    "* Penalizes training error for more complex models (i.e. models with more predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = pd.read_csv('Boston.csv')\n",
    "boston.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston.iloc[:,0:-1].values\n",
    "y = boston.iloc[:,-1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 1234)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "model = LinearRegression().fit(X_train,y_train)\n",
    "yhat = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = X[:,0:2]\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y, test_size = 0.25, random_state = 1234)\n",
    "print(X_train2.shape, X_test2.shape, y_train2.shape, y_test2.shape)\n",
    "\n",
    "model2 = LinearRegression().fit(X_train2,y_train2)\n",
    "yhat2 = model2.predict(X_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjusted $R^2$: \n",
    "\n",
    "* Can't use $R^2$ since it will always decrease as the number of predictors increases\n",
    "    \n",
    "$$\\text{Adjusted }R^2 = 1 - \\frac{RSS/(n - d - 1)}{TSS/(n - 1)} = 1 - \\frac{(1 - R^2)(n-1)}{(n - d -1)}$$\n",
    "\n",
    "n: number of observations  \n",
    "d: number of predictors(include intercept)  \n",
    "RSS: Residual Sum of Squares  \n",
    "TSS: Total Sum of Squares  \n",
    "\n",
    "* Adjusted R2 is always less than or equal to R2. \n",
    "    - = 1 indicates a model that perfectly predicts the target values \n",
    "    - <= 0 indicates a model that has no predictive value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rss(y,yhat):\n",
    "    return np.sum((y - yhat)**2)\n",
    "    \n",
    "def tss(y):\n",
    "    return(np.sum((y - np.mean(y))**2))\n",
    "\n",
    "def R_squared(y,yhat):\n",
    "    return(1 - (rss(y,yhat)/tss(y)))\n",
    "\n",
    "def adjr2_1(y,yhat,d):\n",
    "    n = len(y)\n",
    "    return 1 - ((rss(y,yhat)/(n-d-1))/(tss(y)/(n-1)))\n",
    "\n",
    "def adjr2_2(y,yhat,d):\n",
    "    n = len(y)\n",
    "    return 1 - (((1-R_squared(y,yhat))*(n-1))/(n-d-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_squared(y_train,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjr2_1(y_train,yhat,X.shape[1]),adjr2_2(y_train,yhat,X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_test = model.predict(X_test)\n",
    "R_squared(y_test,yhat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "#### Akaike Information Criteria (AIC)\n",
    "\n",
    "* Value only meaningful in comparison to other models\n",
    "* Lowest AIC is the best\n",
    "\n",
    "$$AIC = -2logL+ 2d$$ \n",
    "\n",
    "L: Maximum Likelihood Estimate  \n",
    "d: number of predictors(include intercept)  \n",
    "\n",
    "* For OLS Linear Regression\n",
    "\n",
    "$$AIC = nlog(RSS/n) + 2d$$\n",
    "\n",
    "n: number of observations  \n",
    "d: number of predictors(include intercept)  \n",
    "RSS: Residual Sum of Squares \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aic(y,yhat,d):\n",
    "    n = len(y)\n",
    "    return n*np.log(rss(y,yhat)/n) + 2*d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aic(y_train,yhat,X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aic(y_train2,yhat2,X_train2.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian Information Criteria (BIC)\n",
    "\n",
    "* Value only meaningful in comparison to other models\n",
    "* Lowest BIC is the best\n",
    "* Generally a heavier penalty than AIC for more predictors\n",
    "\n",
    "$$BIC = -2log(L)+ dlog(n)$$\n",
    "\n",
    "L: Maximum Likelihood Estimate  \n",
    "n: number of observations  \n",
    "d: number of predictors(include intercept)  \n",
    "\n",
    "* For OLS Linear Regression\n",
    "\n",
    "$$BIC = nlog(RSS/n) + dlog(n)$$\n",
    "\n",
    "n: number of observations  \n",
    "d: number of predictors(include intercept)  \n",
    "RSS: Residual Sum of Squares \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bic(y,yhat,d):\n",
    "    n = len(y)\n",
    "    return n*np.log(rss(y,yhat)/n) + d*np.log(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic(y_train,yhat,X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic(y_train2,yhat2,X2.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = LinearRegression().fit(X,y)\n",
    "y_hat = m.predict(X)\n",
    "a = aic(y,y_hat,X.shape[1])\n",
    "b = bic(y,y_hat,X.shape[1])\n",
    "a,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "\n",
    "https://math.stackexchange.com/questions/2093369/bayesian-information-criterion-derivation-for-linear-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
