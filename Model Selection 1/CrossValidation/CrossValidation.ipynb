{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports for Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score #k-Fold Cross Validation\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "## Model Validation Methods\n",
    "\n",
    "* Holdout\n",
    "    - Holdout Validation\n",
    "* K-fold Cross-Validation\n",
    "    - Leave-One-Out Cross-Validation\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holdout \n",
    "\n",
    "* Different definitions of validation set\n",
    "\n",
    "#### Validation set as test set (what we have been doing)\n",
    "\n",
    "* Randomly divide training set into two parts\n",
    "    - Training set\n",
    "    - Test set (also called validation or hold-out) set\n",
    "* train_test_split function in sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Holdout Validation\n",
    "\n",
    "* Separate validation set to determine hyperparameters\n",
    "\n",
    "* Split data into three sets: train, validation, test\n",
    "    - Training data: learn model parameters\n",
    "    - Validation set: Determine optimum hyperparameters\n",
    "    - Test set: prediction of new data\n",
    "* Trains model on less data\n",
    "    - Generally better to train on as much data as possible\n",
    "    - Often don't have enough data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning using validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = sns.load_dataset('iris')\n",
    "X = iris.iloc[:, 0:4].values\n",
    "y = iris.iloc[:, 4].values\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X, y, \n",
    "                                                 test_size = 0.25,\n",
    "                                                 stratify=y,\n",
    "                                                 random_state=4)\n",
    "X_train2,X_val,y_train2,y_val = train_test_split(X_train,y_train,\n",
    "                                                 test_size = .25,\n",
    "                                                 stratify=y_train,\n",
    "                                                 random_state=4)\n",
    "\n",
    "#Scale featues\n",
    "sc = StandardScaler()\n",
    "X_train2 = sc.fit_transform(X_train2)\n",
    "X_val = sc.transform(X_val)\n",
    "X_train2.shape,X_val.shape,y_train2.shape,y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = (.1,1.0,10.0,100.0)\n",
    "scores = np.zeros(len(parameters))\n",
    "for i,param in enumerate(parameters):\n",
    "    svc_model = SVC(C = param, kernel = 'linear', random_state = 1234)\n",
    "    svc_model.fit(X_train2, y_train2)\n",
    "    scores[i] = svc_model.score(X_val,y_val)\n",
    "print(scores)\n",
    "best_C = parameters[np.argmax(scores)]\n",
    "print(f'Best parameter is {best_C}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refit  and test model with best hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale featues\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape\n",
    "\n",
    "final_model = SVC(C = best_C, kernel = 'linear', random_state = 1234)\n",
    "final_model.fit(X_train2, y_train2)\n",
    "final_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Potential Drawbacks of Holdout Approach\n",
    "\n",
    "* Highly variable\n",
    "    - Depends on which observations are included in the test set  \n",
    "    \n",
    "* Overestimates test error rate for entire data set \n",
    "    - Since trained on fewer observations\n",
    "    - Increased bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variability using single sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Auto.csv\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.loc[:,\"horsepower\"].values\n",
    "X = np.array([x**(n+1) for n in range(5)]).transpose()\n",
    "y = df.loc[:,\"mpg\"].values\n",
    "X[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_epoch(X,y,degree):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size = 0.20)\n",
    "    models = [LinearRegression() for i in range(degree)]\n",
    "    mses = np.zeros(degree)\n",
    "    for i in range(degree):\n",
    "        models[i].fit(X_train[:,0:(i+1)], y_train)\n",
    "        preds = models[i].predict(X_test[:,0:(i+1)])\n",
    "        mses[i] = np.mean((y_test - preds)**2)\n",
    "    return mses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 4\n",
    "num_degrees = 5\n",
    "mses = [one_epoch(X,y,num_degrees) for i in range(num_epochs)]\n",
    "print(f'Degree with lowest MSE {list(map(np.argmin,mses))}')\n",
    "msesT = np.array(mses).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize = (12,6))\n",
    "x = (1,2,3,4)\n",
    "legend = []\n",
    "for i in range(5):\n",
    "    ax.plot(x,msesT[i],'o-')\n",
    "    legend.append(f'degree {i}')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend((legend))\n",
    "plt.title(f\"Variablity due to random sampling - {5} degrees\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize = (12,6))\n",
    "x = range(1,6)\n",
    "legend = []\n",
    "for i in range(num_epochs):\n",
    "    ax.plot(x,mses[i],'o-')\n",
    "    legend.append(f'Iteration {i}')\n",
    "plt.xlabel(\"Degree\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend((legend))\n",
    "plt.title(f\"Variablity due to random sampling - {num_epochs} iterations\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "\n",
    "* Used for evaluating the model's test error to \n",
    "    - Evaluate the model's performance (model assessment)\n",
    "    - Select the appropriate level of flexibility (model selection)\n",
    "    \n",
    "![](k-fold.png)\n",
    "$$\\text{Figure 2. 5-fold Cross Validation}$$    \n",
    "    \n",
    "#### Cross-Validation is a resampling method\n",
    "\n",
    "* Given a training set, repeatedly draw samples from that set and refit the model on each sample to gain additional information about the fitted model\n",
    "* Can be computationally expensive but with todays computing power resampling methods are tractable.\n",
    "* Cross-Validation and Bootstrap(covered in Ensemble methods)\n",
    "\n",
    "#### Model Assessment ( Accuracy/Test Error Rate)\n",
    " \n",
    "* Accuracy will vary depending on the particular sample. \n",
    "* More complex models will vary more from sample to sample\n",
    "* Cross-Validation will improve accuracy by reducing bias\n",
    " \n",
    "#### Used in Model Selection to determine the best hyperparameters\n",
    " \n",
    "* Two types of parameters:\n",
    "    - Learned by model\n",
    "    - Set by modeler (hyperparameters)\n",
    " \n",
    "* Determining the optimum value for a hyperparameter\n",
    "    - K in KNN\n",
    "    - C,$\\gamma$ in SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-fold Cross-Validation \n",
    "\n",
    "![](grid_search.png)\n",
    "$$\\text{Figure 1. Cross-Validation Workflow}$$\n",
    "\n",
    "\n",
    "#### Algorithm\n",
    "\n",
    "1. Obtain a dataset\n",
    "    - Shuffle the dataset (optional) \n",
    "2. Randomly divide the data into k groups or folds of approximately equal size  \n",
    "3. For each of the k folds  \n",
    "    a. Make it the validation set  \n",
    "    b. Fit learning method on k-1 remaining folds  \n",
    "    c. Predict the validation set  \n",
    "    d. Calculate Cross Validation score on the MSE of validation set  \n",
    "4. Average the Cross Validation scores for a final performance measure \n",
    "\n",
    "<div style=\"font-size: 115%;\">\n",
    "$$CV_{(k)} = \\frac{1}{k}\\sum^k_{i}MSE_i$$\n",
    "</div>\n",
    "\n",
    "* Each observation in the original sample is used once in the validation set and k-1 times in the training set\n",
    "* Lower bias than a simple train/test split.\n",
    "    - Less prone to underestimate the test error\n",
    "* Any scaling or tuning of hyperparameters must be done within step three to prevent data leakage\n",
    "* k = 5 or k = 10 have been found to produce the best results (i.e. best bias-variance tradeoff)\n",
    "    - k = 1 is the simple train/test split that we have been doing\n",
    "    - k = n is called Leave-One-Out Cross Validation (see below)\n",
    "* Stratified Cross Validation is used in Classification.\n",
    "    - Each fold has the same proportion of observations with a given categorical value.\n",
    "* Repeated Cross Validation: Repeat the Cross Validation procedure N times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-fold Cross Validation in Classification\n",
    "\n",
    "* Use number of misclassifications to quantify test error\n",
    "\n",
    "<div style=\"font-size: 115%;\">\n",
    "$$CV_{(k)} = \\frac{1}{k}\\sum^k_{i}I(y_i\\ne{\\hat{y}_i})$$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leave-One-Out Cross Validation\n",
    " \n",
    "* Given $(x_1,y_1)$,$(x_2,y_2)$,...,$(x_n,y_n)$\n",
    "* Let: $(x_1,y_1)$ be the validation set and $(x_2,y_2)$,...,$(x_n,y_n)$ be the training set\n",
    "* Fit the model on the training set and calculate $MSE_1$\n",
    "    - Predict $\\hat{y_1}$ based on $x_1$\n",
    "        - $MSE_1 = mean(y_1 - \\hat{y_1})^2)$\n",
    "    - Repeat for 2,...,n\n",
    "    \n",
    "<div style=\"font-size: 115%;\">\n",
    "$$CV_{(n)} = \\frac{1}{n}\\sum^n_{i}MSE_i$$\n",
    "</div>\n",
    "\n",
    "* Less bias since uses almost all the data in the training set\n",
    "* No randomness in training/test set splits\n",
    "* But can be computationally expensive and has high variance because:\n",
    "    - Averaging the ouputs of n fitted models trained on datasets that are highly correlated. \n",
    "    - Variance of correlated variables higher than for non-correlated variables\n",
    "\n",
    "$$Var(X + Y) = Var(X) + Var(Y) + 2\\cdot{Cov(X,Y)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn Cross-Validation\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('PurchaseData.csv')\n",
    "X = dataset.iloc[:, [1, 2]].values\n",
    "y = dataset.iloc[:, 3].values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size = 0.25,\n",
    "                                                    random_state = 12,\n",
    "                                                    stratify = y)\n",
    "\n",
    "#Scale featues\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Kernel SVM to the Training set\n",
    "\n",
    "svc_model = SVC(kernel = 'rbf', random_state = 1234)\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict test data\n",
    "y_pred = svc_model.predict(X_test)\n",
    "\n",
    "# Make the Confusion Matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy = np.trace(cm)/np.sum(cm)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying k-Fold Cross Validation\n",
    "\n",
    "n_folds = 10\n",
    "\n",
    "# score function from SVC\n",
    "scores = cross_val_score(estimator = SVC(), X = X_train, y = y_train, cv = n_folds)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,11),scores,\"o-\")\n",
    "print(\"Mean accuracy: \",scores.mean())\n",
    "print(\"Stanard Deviation of accuracies: \",scores.std())\n",
    "print(f'95% Confidence Interval: {round(scores.mean(),3)} +/- {round(2*scores.std(),3)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search cross validation\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "\n",
    "* Search for the optimal hyperparameter.\n",
    "\n",
    "* Optimal is the one with the best Cross Validation score\n",
    "\n",
    "* Parameters\n",
    "    - param_grid: dictionary of hyperparamters and values to search over\n",
    "    - estimator: the model object\n",
    "    - cv: the number of cv folds\n",
    "    - scoring: \"accuracy\" for classification, \"r2\" for regression\n",
    "        - calls accuracy_score or r2_score\n",
    "* Result attributes\n",
    "    - best_score_\n",
    "    - best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search Python\n",
    "# Applying Grid Search to find the best model and the best parameters\n",
    "\n",
    "parameters = [{'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "              {'C': [1, 10, 100, 1000], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]\n",
    "grid_search = GridSearchCV(estimator = SVC(),\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           iid = 'False',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(\"Best accuracy: \", best_accuracy)\n",
    "print(\"Best parameters: \", best_parameters )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = SVC(C = 10, kernel = 'rbf', gamma = 0.3)\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict test data\n",
    "y_pred = svc_model.predict(X_test)\n",
    "\n",
    "# Make the Confusion Matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy = np.trace(cm)/np.sum(cm)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figures\n",
    "\n",
    "Figure 1: Sklearn Cross-Validation Users Guide\n",
    "\n",
    "Figures 2: \"An Introduction to Statistical Learning, with applications in R\" (Springer, 2013) with permission from the authors: G. James, D. Witten, T. Hastie and R. Tibshirani "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
