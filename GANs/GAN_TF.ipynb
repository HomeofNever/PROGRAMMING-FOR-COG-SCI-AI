{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "U91-upG3aCG-"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from imutils import build_montages\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os,sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "klEGNusAaCG_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Reshape\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "95fzRFLdaCHA"
   },
   "outputs": [],
   "source": [
    "def build_generator(dim, depth, channels=1, \n",
    "                    inputDim=100,\n",
    "                    outputDim=512):\n",
    "    model = Sequential()\n",
    "    # Two Fully Connected layers with Batch Normalization\n",
    "    model.add(Dense(input_dim=inputDim, units=outputDim))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "  \n",
    "    model.add(Dense(dim * dim * depth))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # Reshape the output of the previous layer, upsample\n",
    "    # apply a transposed convolution (i.e. deconvolution), RELU, and BN\n",
    "    model.add(Reshape((dim, dim, depth))) #Input shape\n",
    "    model.add(Conv2DTranspose(32, (5, 5), strides=(2, 2),\n",
    "                              padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    # Apply another upsample and transposed convolution, but\n",
    "    # with TANH activation\n",
    "    model.add(Conv2DTranspose(channels, (5, 5), strides=(2, 2),\n",
    "                              padding=\"same\"))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "95fzRFLdaCHA"
   },
   "outputs": [],
   "source": [
    "def build_discriminator(width, height, depth, alpha=0.2):\n",
    "    model = Sequential()\n",
    "    # Two conv2d layers\n",
    "    model.add(Conv2D(32, (5, 5), padding=\"same\", strides=(2, 2),\n",
    "                     input_shape=(height, width, depth)))\n",
    "    model.add(LeakyReLU(alpha=alpha))\n",
    "    model.add(Conv2D(64, (5, 5), padding=\"same\", strides=(2, 2)))\n",
    "    model.add(LeakyReLU(alpha=alpha))\n",
    "    \n",
    "    # Flatten Layer\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    #  One linear hidden layer with leaky relu\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=alpha))\n",
    "    # output layer with sigmoid activation\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Fashion MNIST dataset\n",
    "* Stack the training and testing data points so we have additional training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_UCS0w3CaCHA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((trainX, _), (testX, _)) = fashion_mnist.load_data()\n",
    "trainImages = np.concatenate([trainX, testX])\n",
    "trainImages.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_UCS0w3CaCHA"
   },
   "source": [
    "#### Preprocess\n",
    "\n",
    "* Add in an extra dimension for the channel and scale the images\n",
    "into the range [-1, 1] (which is the range of the tanh function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_UCS0w3CaCHA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 28, 28, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainImages = np.expand_dims(trainImages, axis=-1)\n",
    "trainImages = (trainImages.astype(\"float\") - 127.5) / 127.5\n",
    "trainImages.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build models and compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Df-uT0d4aCHA"
   },
   "outputs": [],
   "source": [
    "lr = 0.0002\n",
    "num_epochs = 50\n",
    "\n",
    "G_model = build_generator(7, 64, channels=1)\n",
    "D_model = build_discriminator(28, 28, 1)\n",
    "D_model.compile(loss=\"binary_crossentropy\", \n",
    "                optimizer=Adam(lr=lr,beta_1=0.5,decay=lr/num_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               51712     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3136)              1608768   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 3136)              12544     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 14, 14, 32)        51232     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 28, 28, 1)         801       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 1,727,233\n",
      "Trainable params: 1,719,873\n",
      "Non-trainable params: 7,360\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "G_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 14, 14, 32)        832       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 7, 7, 64)          51264     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,658,753\n",
      "Trainable params: 1,658,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "D_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the GAN model\n",
    "* Set the discriminator to **not** be trainable, i.e. freeze the weights\n",
    "* Compose  discriminator with the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "I-kHs4JvaCHA"
   },
   "outputs": [],
   "source": [
    "D_model.trainable = False\n",
    "ganInput = Input(shape=(100,))\n",
    "ganOutput = D_model(G_model(ganInput))\n",
    "GAN_model = Model(ganInput, ganOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 28, 28, 1)         1727233   \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 1)                 1658753   \n",
      "=================================================================\n",
      "Total params: 3,385,986\n",
      "Trainable params: 1,719,873\n",
      "Non-trainable params: 1,666,113\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "GAN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "I-kHs4JvaCHA"
   },
   "outputs": [],
   "source": [
    "\n",
    "GAN_model.compile(\n",
    "            loss=\"binary_crossentropy\", \n",
    "            optimizer=Adam(lr=lr, beta_1=0.5, decay=lr/num_epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-V7O_HmZaCHA",
    "outputId": "3e1ea625-1f41-453f-d631-e25acbe38ffc"
   },
   "outputs": [],
   "source": [
    "def prepare_images(G,imageBatch, batch_size):\n",
    "    ''' Select the next batch of images, then randomly generate\n",
    "        noise for the generator to predict on.\n",
    "        Construct class labels for the discriminator, and shuffle\n",
    "        the data'''\n",
    "    noise = np.random.uniform(-1, 1, size=(batch_size, 100))\n",
    "    # Generate images using the noise + generator model\n",
    "    genImages = G.predict(noise, verbose=0)\n",
    "    X = np.concatenate((imageBatch, genImages))#Concat real and generated\n",
    "    y = ([1] * batch_size) + ([0] * batch_size)\n",
    "    y = np.reshape(y, (-1,))\n",
    "    return shuffle(X, y)\n",
    "\n",
    "def GAN_output(G,epoch,noise,output):\n",
    "    '''\n",
    "    Visualize the output of the generator model on our benchmark data\n",
    "    Make predictions on the benchmark noise, scale it back\n",
    "    to the range [0, 255], and generate the montage'''\n",
    "    fp = [output, f\"epoch_{epoch + 1:03}_output.png\"]   \n",
    "    images = G.predict(noise)\n",
    "    images = ((images * 127.5) + 127.5).astype(\"uint8\")\n",
    "    images = np.repeat(images, 3, axis=-1)\n",
    "    vis = build_montages(images, (28, 28), (16, 16))[0]\n",
    "    # write the visualization to disk\n",
    "    fp = os.path.sep.join(fp)\n",
    "    res = cv2.imwrite(fp, vis)\n",
    "    print(fp,' ',res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-V7O_HmZaCHA",
    "outputId": "3e1ea625-1f41-453f-d631-e25acbe38ffc"
   },
   "outputs": [],
   "source": [
    "def train_gan(G,D,GAN,trainImages,num_epochs,outDir):\n",
    "    benchmarkNoise = np.random.uniform(-1, 1, size=(256, 100))\n",
    "    batch_size = 128\n",
    "    batchesPerEpoch = int(trainImages.shape[0]/batch_size)\n",
    "    for epoch in range(0, num_epochs):\n",
    "        for i in range(0, batchesPerEpoch):\n",
    "            imageBatch = trainImages[i*batch_size:(i+1)*batch_size]\n",
    "            X,y = prepare_images(G,imageBatch,batch_size)\n",
    "            # Train the discriminator on the data\n",
    "            D_Loss = D.train_on_batch(X, y)\n",
    "\n",
    "            # Train the generator via the adversarial model by\n",
    "            # (1) generating random noise and \n",
    "            # (2) training generator with the discriminator weights frozen\n",
    "            noise = np.random.uniform(-1, 1, (batch_size, 100))\n",
    "            fakeLabels = [1] * batch_size\n",
    "            fakeLabels = np.reshape(fakeLabels, (-1,))\n",
    "            GAN_Loss = GAN.train_on_batch(noise, fakeLabels)\n",
    "            if not i%150:\n",
    "                print(\n",
    "                f\"Epoch {epoch+1}_{i}: D loss={D_Loss:.4f}, GAN loss={GAN_Loss:.4f}\")\n",
    "          \n",
    "            # Write predicted images to disk\n",
    "            if outDir and (i == batchesPerEpoch - 1): # End of epoch\n",
    "                GAN_output(G,epoch,benchmarkNoise,outDir)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1_0: D loss=0.6798, GAN loss=0.5815\n",
      "Epoch 1_150: D loss=0.0001, GAN loss=0.0006\n",
      "Epoch 1_300: D loss=0.3897, GAN loss=1.2692\n",
      "Epoch 1_450: D loss=0.5232, GAN loss=1.7431\n",
      "./Images/epoch_0001_output.png   True\n",
      "Epoch 2_0: D loss=0.5011, GAN loss=0.7400\n",
      "Epoch 2_150: D loss=0.5669, GAN loss=0.9814\n",
      "Epoch 2_300: D loss=0.4962, GAN loss=1.2782\n",
      "Epoch 2_450: D loss=0.6098, GAN loss=0.7417\n",
      "./Images/epoch_0002_output.png   True\n",
      "Epoch 3_0: D loss=0.5666, GAN loss=1.2822\n",
      "Epoch 3_150: D loss=0.5758, GAN loss=0.9827\n",
      "Epoch 3_300: D loss=0.5449, GAN loss=0.9618\n",
      "Epoch 3_450: D loss=0.5583, GAN loss=0.8353\n",
      "./Images/epoch_0003_output.png   True\n",
      "Epoch 4_0: D loss=0.6354, GAN loss=1.4942\n",
      "Epoch 4_150: D loss=0.5756, GAN loss=1.0160\n",
      "Epoch 4_300: D loss=0.5902, GAN loss=0.9631\n",
      "Epoch 4_450: D loss=0.5845, GAN loss=0.9972\n",
      "./Images/epoch_0004_output.png   True\n",
      "Epoch 5_0: D loss=0.5763, GAN loss=0.9283\n",
      "Epoch 5_150: D loss=0.6029, GAN loss=0.8882\n",
      "Epoch 5_300: D loss=0.5734, GAN loss=0.9757\n",
      "Epoch 5_450: D loss=0.5835, GAN loss=0.7189\n",
      "./Images/epoch_0005_output.png   True\n",
      "Epoch 6_0: D loss=0.6013, GAN loss=1.0069\n",
      "Epoch 6_150: D loss=0.6275, GAN loss=0.7021\n",
      "Epoch 6_300: D loss=0.6070, GAN loss=0.7518\n",
      "Epoch 6_450: D loss=0.6171, GAN loss=0.9201\n",
      "./Images/epoch_0006_output.png   True\n",
      "Epoch 7_0: D loss=0.6209, GAN loss=0.9962\n",
      "Epoch 7_150: D loss=0.6315, GAN loss=0.9464\n",
      "Epoch 7_300: D loss=0.6351, GAN loss=0.7371\n",
      "Epoch 7_450: D loss=0.6145, GAN loss=0.8076\n",
      "./Images/epoch_0007_output.png   True\n",
      "Epoch 8_0: D loss=0.6261, GAN loss=0.8513\n",
      "Epoch 8_150: D loss=0.6310, GAN loss=0.8494\n",
      "Epoch 8_300: D loss=0.5913, GAN loss=0.8941\n",
      "Epoch 8_450: D loss=0.6506, GAN loss=0.9993\n",
      "./Images/epoch_0008_output.png   True\n",
      "Epoch 9_0: D loss=0.6247, GAN loss=0.8429\n",
      "Epoch 9_150: D loss=0.6464, GAN loss=0.7665\n",
      "Epoch 9_300: D loss=0.6167, GAN loss=0.8738\n",
      "Epoch 9_450: D loss=0.6659, GAN loss=0.8319\n",
      "./Images/epoch_0009_output.png   True\n",
      "Epoch 10_0: D loss=0.6314, GAN loss=0.7216\n",
      "Epoch 10_150: D loss=0.6304, GAN loss=0.9333\n",
      "Epoch 10_300: D loss=0.6345, GAN loss=0.6161\n",
      "Epoch 10_450: D loss=0.6373, GAN loss=0.8212\n",
      "./Images/epoch_0010_output.png   True\n",
      "Epoch 11_0: D loss=0.6095, GAN loss=0.8429\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c4fd5bb32465>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mtrainImages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m           \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m           output)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-f9f81a07f4f3>\u001b[0m in \u001b[0;36mtrain_gan\u001b[0;34m(G, D, GAN, trainImages, num_epochs, outDir)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mfakeLabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mfakeLabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfakeLabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mGAN_Loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfakeLabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 print(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1693\u001b[0m                                                     class_weight)\n\u001b[1;32m   1694\u001b[0m       \u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "output = \"Images\"\n",
    "train_gan(G_model,D_model,GAN_model,\n",
    "          trainImages,\n",
    "          num_epochs,\n",
    "          output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBP8ZIFBaCG-"
   },
   "source": [
    "### References\n",
    "\n",
    "\n",
    "https://www.pyimagesearch.com/2020/11/16/gans-with-keras-and-tensorflow/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "GAN_TF.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
