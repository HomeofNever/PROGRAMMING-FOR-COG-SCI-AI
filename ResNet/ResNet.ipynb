{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlexNet\n",
    "\n",
    "![](alexnet.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Same Convolution\n",
    "\n",
    "* A Same Convolution is a type of convolution where the output matrix is of the same dimension as the input matrix.\n",
    "* For a nxn input matrix A and a fxf filter matrix F: the output of the convolution A*F is of dimension \n",
    "$$\\left(\\frac{n*2p-f}{s}\\right)+1 \\text{ x } \\left(\\frac{n*2p-f}{s}\\right)+1$$\n",
    "s = stride   \n",
    "p = padding  \n",
    "* For a same convolution:\n",
    "    - s = 1,  \n",
    "    - p = $\\frac{f - 1}{2}$, and   \n",
    "    - f is an odd number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG-16\n",
    "\n",
    "* Karen Simonyan and Andrew Zisserman (2014). Visual Geometry Group Lab of Oxford University\n",
    "\n",
    "![](VGG.png)\n",
    "\n",
    "* ~138 Million parameters\n",
    "* 3x3 filters\n",
    "* Stride = 1\n",
    "* All convolutions are same convolutions\n",
    "* Number of filters 64->128->256->512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet\n",
    "\n",
    "* He,Zhang,Ren and Sun (2015) [Deep Residual Learning for Image Recognition. ](https://arxiv.org/abs/1512.03385)\n",
    "\n",
    "* Why doesn't adding more layers improve Training and Test Error?\n",
    "    - Learning F(x) = 0 because of weight decay, small random initialization, L2 regularization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](MoreLayers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Blocks\n",
    "\n",
    "* Solution: Learn F(x) + x \n",
    "\n",
    "![](ResBlock.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size: 115%;\">\n",
    "$$a^{l+2} = ReLU((W^{l+2}\\cdot{a^{l+1}}+b^{l+2}) + a^l)$$\n",
    "</div>\n",
    "\n",
    "* If the weights and bias = 0 (because of weight decay, small random initialization, L2 regularization) then\n",
    "\n",
    "<div style=\"font-size: 115%;\">\n",
    "$$ a^l = ReLU(a^l) = a^l$$\n",
    "</div>\n",
    "\n",
    "* The Residual block learns the indentity function\n",
    "* Called a \"skip\" or \"short cut\" connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ResNet Architecture\n",
    "\n",
    "![](ResNet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1x1 Convolutions\n",
    "\n",
    "* Dotted line in the ResNet architecture are where the number of channels increases\n",
    "* 1x1 Convolution projects to a higher number of channels but doesn't change the input size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_params(n,m,l,k):\n",
    "    '''Number of parameters conv2d_2\n",
    "        n,m = shape of kernel\n",
    "        l = number of inputs\n",
    "        k = number of outputs\n",
    "        num_param = (n*m*l+1)*k'''\n",
    "    print(f'(Kernel=({n}x{m}) * num_in={l} + 1)) * num_out={k} = {(n*m*l+1)*k}')\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Kernel=(3x3) * num_in=3 + 1)) * num_out=512 = 14336\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 256, 256, 512)     14336     \n",
      "=================================================================\n",
      "Total params: 14,336\n",
      "Trainable params: 14,336\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(512, (3,3), padding='same', \n",
    "                 activation='relu', input_shape=(256, 256, 3)))\n",
    "# summarize model\n",
    "num_params(3,3,3,512)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv2D(512, (3,3), padding='same', activation='relu', input_shape=(256, 256, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1x1, number of channels in equals number of channels out\n",
    "\n",
    "* Size of feature map doesn't cange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Kernel=(1x1) * num_in=512 + 1)) * num_out=512 = 262656\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 256, 256, 512)     14336     \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 256, 256, 512)     262656    \n",
      "=================================================================\n",
      "Total params: 276,992\n",
      "Trainable params: 276,992\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(Conv2D(512, (1,1), activation='relu'))\n",
    "num_params(1,1,512,512)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1x1, number of channels decreases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Kernel=(1x1) * num_in=512 + 1)) * num_out=64 = 32832\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 256, 256, 512)     14336     \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 256, 256, 512)     262656    \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 256, 256, 64)      32832     \n",
      "=================================================================\n",
      "Total params: 309,824\n",
      "Trainable params: 309,824\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(Conv2D(64, (1,1), activation='relu'))\n",
    "num_params(1,1,512,64)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1x1, number of channels increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Kernel=(1x1) * num_in=64 + 1)) * num_out=512 = 33280\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 256, 256, 512)     14336     \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 256, 256, 512)     262656    \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 256, 256, 64)      32832     \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 256, 256, 512)     33280     \n",
      "=================================================================\n",
      "Total params: 343,104\n",
      "Trainable params: 343,104\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(Conv2D(512, (1,1), activation='relu'))\n",
    "# summarize model\n",
    "num_params(1,1,64,512)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Use 1x1 convolution to reduce number of channels before applying larger convolution\n",
    "\n",
    "input (256 depth) -> 1x1 convolution (64 depth) -> 4x4 convolution (256 depth)\n",
    "\n",
    "input (256 depth) -> 4x4 convolution (256 depth)\n",
    "\n",
    "Bottom ~3.7 times slower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "  \n",
    "  def __init__(self,input_channels, num_channels, use_1x1conv=False, strides=1, **kwargs):\n",
    "    super(Residual, self).__init__(**kwargs)\n",
    "    self.conv1 = nn.Conv2d(input_channels, num_channels,kernel_size=3, padding=1, stride=strides)\n",
    "    self.conv2 = nn.Conv2d(num_channels, num_channels, kernel_size=3, padding=1)\n",
    "    if use_1x1conv:\n",
    "      self.conv3 = nn.Conv2d(input_channels, num_channels, kernel_size=1, stride=strides)\n",
    "    else:\n",
    "      self.conv3 = None\n",
    "    self.bn1 = nn.BatchNorm2d(num_channels)\n",
    "    self.bn2 = nn.BatchNorm2d(num_channels)\n",
    "    self.relu = nn.ReLU(inplace=True)\n",
    "  \n",
    "  def forward(self, X):\n",
    "    Y = self.relu(self.bn1(self.conv1(X)))\n",
    "    Y = self.bn2(self.conv2(Y))\n",
    "    if self.conv3:\n",
    "      X = self.conv3(X)\n",
    "    Y += X\n",
    "    Y = self.relu(Y)\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_block(input_channels, num_channels, num_residuals, first_block=False):\n",
    "  blk = []\n",
    "  for i in range(num_residuals):\n",
    "    if i == 0 and not first_block:\n",
    "      blk.append(Residual(input_channels, num_channels, use_1x1conv=True, strides=2))\n",
    "    else:\n",
    "      blk.append(Residual(num_channels, num_channels))\n",
    "  return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "                    nn.BatchNorm2d(64),\n",
    "                    nn.ReLU(),\n",
    "                    nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2=nn.Sequential(*resnet_block(64,64,2,first_block=True))\n",
    "b3=nn.Sequential(*resnet_block(64,128,2))\n",
    "b4=nn.Sequential(*resnet_block(128,256,2))\n",
    "b5=nn.Sequential(*resnet_block(256,512,2))\n",
    "net=nn.Sequential(b1,\n",
    "                  b2,b3,b4,b5,\n",
    "                  nn.AdaptiveMaxPool2d((1,1)),\n",
    "                  nn.Flatten(),\n",
    "                  nn.Linear(512, 10))\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 14, 14]           3,200\n",
      "       BatchNorm2d-2           [-1, 64, 14, 14]             128\n",
      "              ReLU-3           [-1, 64, 14, 14]               0\n",
      "         MaxPool2d-4             [-1, 64, 7, 7]               0\n",
      "            Conv2d-5             [-1, 64, 7, 7]          36,928\n",
      "       BatchNorm2d-6             [-1, 64, 7, 7]             128\n",
      "              ReLU-7             [-1, 64, 7, 7]               0\n",
      "            Conv2d-8             [-1, 64, 7, 7]          36,928\n",
      "       BatchNorm2d-9             [-1, 64, 7, 7]             128\n",
      "             ReLU-10             [-1, 64, 7, 7]               0\n",
      "         Residual-11             [-1, 64, 7, 7]               0\n",
      "           Conv2d-12             [-1, 64, 7, 7]          36,928\n",
      "      BatchNorm2d-13             [-1, 64, 7, 7]             128\n",
      "             ReLU-14             [-1, 64, 7, 7]               0\n",
      "           Conv2d-15             [-1, 64, 7, 7]          36,928\n",
      "      BatchNorm2d-16             [-1, 64, 7, 7]             128\n",
      "             ReLU-17             [-1, 64, 7, 7]               0\n",
      "         Residual-18             [-1, 64, 7, 7]               0\n",
      "           Conv2d-19            [-1, 128, 4, 4]          73,856\n",
      "      BatchNorm2d-20            [-1, 128, 4, 4]             256\n",
      "             ReLU-21            [-1, 128, 4, 4]               0\n",
      "           Conv2d-22            [-1, 128, 4, 4]         147,584\n",
      "      BatchNorm2d-23            [-1, 128, 4, 4]             256\n",
      "           Conv2d-24            [-1, 128, 4, 4]           8,320\n",
      "             ReLU-25            [-1, 128, 4, 4]               0\n",
      "         Residual-26            [-1, 128, 4, 4]               0\n",
      "           Conv2d-27            [-1, 128, 4, 4]         147,584\n",
      "      BatchNorm2d-28            [-1, 128, 4, 4]             256\n",
      "             ReLU-29            [-1, 128, 4, 4]               0\n",
      "           Conv2d-30            [-1, 128, 4, 4]         147,584\n",
      "      BatchNorm2d-31            [-1, 128, 4, 4]             256\n",
      "             ReLU-32            [-1, 128, 4, 4]               0\n",
      "         Residual-33            [-1, 128, 4, 4]               0\n",
      "           Conv2d-34            [-1, 256, 2, 2]         295,168\n",
      "      BatchNorm2d-35            [-1, 256, 2, 2]             512\n",
      "             ReLU-36            [-1, 256, 2, 2]               0\n",
      "           Conv2d-37            [-1, 256, 2, 2]         590,080\n",
      "      BatchNorm2d-38            [-1, 256, 2, 2]             512\n",
      "           Conv2d-39            [-1, 256, 2, 2]          33,024\n",
      "             ReLU-40            [-1, 256, 2, 2]               0\n",
      "         Residual-41            [-1, 256, 2, 2]               0\n",
      "           Conv2d-42            [-1, 256, 2, 2]         590,080\n",
      "      BatchNorm2d-43            [-1, 256, 2, 2]             512\n",
      "             ReLU-44            [-1, 256, 2, 2]               0\n",
      "           Conv2d-45            [-1, 256, 2, 2]         590,080\n",
      "      BatchNorm2d-46            [-1, 256, 2, 2]             512\n",
      "             ReLU-47            [-1, 256, 2, 2]               0\n",
      "         Residual-48            [-1, 256, 2, 2]               0\n",
      "           Conv2d-49            [-1, 512, 1, 1]       1,180,160\n",
      "      BatchNorm2d-50            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-51            [-1, 512, 1, 1]               0\n",
      "           Conv2d-52            [-1, 512, 1, 1]       2,359,808\n",
      "      BatchNorm2d-53            [-1, 512, 1, 1]           1,024\n",
      "           Conv2d-54            [-1, 512, 1, 1]         131,584\n",
      "             ReLU-55            [-1, 512, 1, 1]               0\n",
      "         Residual-56            [-1, 512, 1, 1]               0\n",
      "           Conv2d-57            [-1, 512, 1, 1]       2,359,808\n",
      "      BatchNorm2d-58            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-59            [-1, 512, 1, 1]               0\n",
      "           Conv2d-60            [-1, 512, 1, 1]       2,359,808\n",
      "      BatchNorm2d-61            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-62            [-1, 512, 1, 1]               0\n",
      "         Residual-63            [-1, 512, 1, 1]               0\n",
      "AdaptiveMaxPool2d-64            [-1, 512, 1, 1]               0\n",
      "          Flatten-65                  [-1, 512]               0\n",
      "           Linear-66                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 11,178,378\n",
      "Trainable params: 11,178,378\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.06\n",
      "Params size (MB): 42.64\n",
      "Estimated Total Size (MB): 43.71\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net,(1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        \n",
    "def evaluate_accuracy(data_iter, net, device):\n",
    "    \"\"\"Evaluate accuracy of a model\"\"\"\n",
    "    net.eval()  # Switch to evaluation mode for Dropout, BatchNorm etc layers.\n",
    "    acc_sum, n = torch.tensor([0], dtype=torch.float32, device=device), 0\n",
    "    for X, y in data_iter:\n",
    "        # Copy the data to device.\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        with torch.no_grad():\n",
    "            y = y.long()\n",
    "            acc_sum += torch.sum((torch.argmax(net(X), dim=1) == y))\n",
    "            n += y.shape[0]\n",
    "    return acc_sum.item()/n\n",
    "\n",
    "import time\n",
    "def train_resnet(net, train_iter, test_iter, num_epochs, batch_size, device, lr=None):\n",
    "    print('training on', device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train() # Switch to training mode\n",
    "        n, start = 0, time.time()\n",
    "        train_l_sum = torch.tensor([0.0], dtype=torch.float32, device=device)\n",
    "        train_acc_sum = torch.tensor([0.0], dtype=torch.float32, device=device)\n",
    "        for X, y in train_iter:\n",
    "            optimizer.zero_grad()\n",
    "            X, y = X.to(device), y.to(device) \n",
    "            y_hat = net(X) # Forward\n",
    "            loss = criterion(y_hat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                y = y.long()\n",
    "                train_l_sum += loss.float()\n",
    "                train_acc_sum += (torch.sum((torch.argmax(y_hat, dim=1) == y))).float()\n",
    "                n += y.shape[0]\n",
    "\n",
    "        test_acc = evaluate_accuracy(test_iter, net, device) \n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\\\n",
    "            % (epoch + 1, train_l_sum/n, train_acc_sum/n, test_acc, time.time() - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='.',\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='.',\n",
    "    train=False,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True)\n",
    "\n",
    "batch_size = 256\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cpu\n",
      "epoch 1, loss 0.0081, train acc 0.632, test acc 0.440, time 674.2 sec\n",
      "epoch 2, loss 0.0022, train acc 0.796, test acc 0.800, time 672.7 sec\n",
      "epoch 3, loss 0.0017, train acc 0.834, test acc 0.834, time 674.7 sec\n",
      "epoch 4, loss 0.0016, train acc 0.849, test acc 0.856, time 678.6 sec\n",
      "epoch 5, loss 0.0014, train acc 0.863, test acc 0.859, time 675.6 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs, batch_size = 0.05, 5, 256\n",
    "net.apply(init_weights)\n",
    "train_resnet(net, train_loader, test_loader, num_epochs, batch_size, device, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Normalization\n",
    "\n",
    "* Ioffe and Szegedy (2015) [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167)\n",
    "\n",
    "* In each training iteration, BN normalizes the activations of each hidden layer node \n",
    "(on each layer where it is applied) by subtracting its mean and dividing by its standard deviation, estimating both based on the current minibatch.\n",
    "\n",
    "* Batch Normalization transforms the activation at a given layer from $\\mathbf{a}$ to\n",
    "\n",
    "$$\\mathrm{BN}(\\mathbf{a}) = \\mathbf{\\gamma} \\odot \\frac{\\mathbf{a} - \\hat{\\mathbf{\\mu}}}{\\hat\\sigma} + \\mathbf{\\beta}$$\n",
    "\n",
    "Where:  \n",
    "$\\hat{\\mathbf{\\mu}}$ is the estimate of the mean  \n",
    "$\\hat{\\mathbf{\\sigma}}$ is the estimate of the variance   \n",
    "$\\mathbf{\\gamma}$ is coordinate-wise scaling coefficient   \n",
    "$\\mathbf{\\beta}$ is an offset  \n",
    "$\\odot$ is elementwise multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For convolutional layers, batch normalization occurs after the convolution computation and before the application of the activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola, DiveIntoDeepLearning\n",
    "\n",
    "Andrew Ng, DeepLearning.AI\n",
    "\n",
    "Jason Brownlee, A Gentle Introduction to 1×1 Convolutions to Manage Model Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
