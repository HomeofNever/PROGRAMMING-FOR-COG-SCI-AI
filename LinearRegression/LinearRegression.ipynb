{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder,StandardScaler,MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score,mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "* Basis of many more recent and complex learning methods\n",
    "* Quantitative (continuous real-valued, $\\in R^1$) response (Y) as a linear function of one or more features (X)\n",
    "    - e.g. height as a function of weight, temperature as a function of pressure\n",
    "\n",
    "#### Linear Regression Model (single feature)\n",
    "\n",
    "* **Data** ${((x_0,y_0),(x_1,y_1),...,(x_n,y_n)}, x_i \\in R^d, y \\in R$, n is the number of observations (i.e. samples)  \n",
    "\n",
    "\n",
    "* The expected value of Y given X as a linear function of X (i.e. a line)\n",
    "\n",
    "<div style=\"font-size: 125%;\">\n",
    "$$ E[Y|X] = f(X) = b_0 + b_1X$$\n",
    "</div>\n",
    "\n",
    "#### Uses\n",
    "\n",
    "* Explain the relationship between response variable and feature variable(s)\n",
    "    - Strength of association (i.e. the correlation)\n",
    "    - How much of the variance of the response can be explained by the predictors?\n",
    "* Predict the response variable from the feature variables\n",
    "\n",
    "#### Types\n",
    "\n",
    "* Simple Linear Regression\n",
    "    - One quantitative feature\n",
    "* Multivariate Regression\n",
    "    - Two or more features\n",
    "    - Quantitative or categorical features\n",
    "* Polynomial Regression\n",
    "    - Polynomial terms of single feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Simple Linear Regression\n",
    "\n",
    "* Dependent variable (response, outcome variable) y is a function of a single independent (feature, predictor) variable x\n",
    "* y = mx + b, where m is the slope and b is the intercept\n",
    "    - $y,x,b \\in R$\n",
    "* Does y increase or decrease as x increases or decreases and by how much?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "howell = pd.read_csv(\"Howell.csv\",sep=';')\n",
    "howell.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult = howell.query(\"age > 17\")\n",
    "adult.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(adult.height);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabel,ylabel = 'weight','height'\n",
    "plt.scatter(adult.weight, adult.height, color = 'red')\n",
    "plt.title(f'{ylabel} vs. {xlabel}')\n",
    "plt.xlabel(xlabel)\n",
    "plt.ylabel(ylabel);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Missing values:\\n',adult.isnull().sum())\n",
    "print(f'\\nCorrelation: {np.round(np.corrcoef(adult.weight, adult.height)[0,1],3)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model for Simple Linear Regression\n",
    "\n",
    "* Dependent variable y (height) is a linear function of the independent variable x (weight)\n",
    "\n",
    "<div style=\"font-size: 125%;\">\n",
    "$$ y = b_0 + b_1*x + \\epsilon$$\n",
    "</div>\n",
    "\n",
    "y is the dependent variable  \n",
    "x is the independent variable  \n",
    "$b_0$ is the intercept  \n",
    "$b_1$ is the slope  \n",
    "$\\epsilon$ is the error term (noise)\n",
    "\n",
    "#### Fitting the model\n",
    "\n",
    "* The parameters of the model are $b_0$ and $b_1$ \n",
    "* Learn $b_0$ and $b_1$ from the data\n",
    "* $b_0$ and $b_1$ will determine a line through the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal: Find best fitting line\n",
    "\n",
    "* Learn $b_0$ and $b_1$ to find the best fitting line\n",
    "* Use best fitting line to predict new data\n",
    "* The best fitting line is the line with the smallest error $\\epsilon$\n",
    "    - Its an **optimization** problem\n",
    "* We want to fit the linear regression model to the data to estimate the values of the coefficients that minimize the error\n",
    "\n",
    "<div style=\"font-size: 125%;\">\n",
    "$$\\hat{y_i} = \\hat{b}_0 + \\hat{b}_1x_i$$\n",
    "</div>\n",
    "\n",
    "* $x_i$ is the ith value of the predictor\n",
    "* $\\hat{y_i}$ is the predicted response (or fitted value) for observation i\n",
    "* $\\hat{b}_0$ is an estimate of the intercept\n",
    "* $\\hat{b}_1$ is an estimate of the slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sklearn.LinearRegression\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "\n",
    "* Methods\n",
    "    - fit: fit model to training data\n",
    "    - predict: predict new data\n",
    "    - score: R-squared\n",
    "    \n",
    "* intercept_ and coef_ to get the fitted parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create arrays from data frame\n",
    "\n",
    "* x should be 2-dimensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = adult.weight.values.reshape(-1,1)\n",
    "y = adult.height.values\n",
    "\n",
    "X.shape, X.ndim, y.shape,y.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=1234)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create linear model and fit to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print(f'Intercept: {model.intercept_} Slope: {model.coef_[0]} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict new points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = np.array([30.0,45.0,65.0])\n",
    "predictions = model.predict(new.reshape(-1,1)) # Model fitted to 2-d array\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabel,ylabel = 'Weight','Height'\n",
    "\n",
    "plt.scatter(X, y, color = 'red')\n",
    "plt.plot(new,predictions,'bo')\n",
    "plt.title(f'Predict {new}')\n",
    "plt.xlabel(xlabel)\n",
    "plt.ylabel(ylabel);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Line\n",
    "\n",
    "#### Predict each value of test set using the  model fitted to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test) # model.intercept_  + model.coef_[0]* X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_test, y_test, color = 'red') # the data points\n",
    "plt.plot(X_test, yhat, color = 'blue') # the predicted points on the line\n",
    "plt.plot(new,predictions,'bo')\n",
    "plt.title(f'Best Fitting Line, y = {model.intercept_:.2f} + {model.coef_[0]:.2f}*x')\n",
    "plt.xlabel(xlabel)\n",
    "plt.ylabel(ylabel);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinary Least Squares (OLS) (i.e. how the model does it)\n",
    "\n",
    "* Method for estimating the coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residuals: Difference between actual response value $y_i$ and fitted value $\\hat{y}$\n",
    "\n",
    "<div style=\"font-size: 125%;\">\n",
    "$$\\epsilon_i = y_i - \\hat{y_i}$$\n",
    "</div> \n",
    "\n",
    "* Best fitting line is one that makes this prediction error \"as small as possible\" \n",
    "\n",
    "#### Minimize Square Error\n",
    "\n",
    "* One way is to minimize the sum of the squared prediction errors: Ordinary Least Squares method \n",
    "* Find parameters $\\hat{b}_0$ and $\\hat{b}_1$ that minimizes \n",
    "\n",
    "<div style=\"font-size: 125%;\">\n",
    "$$RSS = SSE = \\sum{\\epsilon^2_i} = \\sum{(y_i - \\hat{y_i})^2} = \\sum{(y_i - \\hat{b}_0 + \\hat{b}_1x_i)^2}$$\n",
    "</div>\n",
    "\n",
    " * RSS is called the Residual Sum of Squares, SSE = Sum of Squared Estimate of Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_test, y_test, color = 'red')\n",
    "plt.plot(X_test, yhat, color = 'blue')\n",
    "plt.title('Residuals')\n",
    "plt.xlabel(xlabel)\n",
    "plt.ylabel(ylabel)\n",
    "for i in range(len(yhat)):\n",
    "    plt.plot((X_test[i],X_test[i]),(yhat[i],y_test[i]),'g-') #(x-coordinates from,to) (y-coordinates  from,to)    \n",
    "#plt.savefig(\"Residuals.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Why squared error? why not absolute error>\n",
    " \n",
    "* Distance measure\n",
    "* Smooth function, differentiable\n",
    "\n",
    "#### Least squares estimate for the coefficients $\\hat{b}_0$ and $\\hat{b}_1$\n",
    " \n",
    "* Take the partial derivative with respect to $\\hat{b}_1$, set it to 0 and solve for $\\hat{b}_1$\n",
    "\n",
    "<div style=\"font-size: 125%;\">\n",
    "\n",
    "$$\\frac{\\partial(RSS)}{\\partial(\\hat{b}_1)} = 0$$$$\\hat{b}_1 = \\frac{\\sum^n_{i=1}(x_i-\\bar{x})(y_i-\\bar{y})}{\\sum^n_{i=1}(x_i-\\bar{x})^2}$$\n",
    "\n",
    "$$\\hat{b}_0 = \\bar{y} - \\hat{b}_1\\bar{x}$$\n",
    "</div>\n",
    "\n",
    "$\\bar{x}$ - mean of x  \n",
    "$\\bar{y}$ - mean of y\n",
    "\n",
    "#### Note:\n",
    "\n",
    "<div style=\"font-size: 125%;\">\n",
    "$$\\hat{b}_1 = \\frac{COV(x,y)}{VAR(x)}$$\n",
    "</div>\n",
    "\n",
    "#### Derivation\n",
    "\n",
    "https://are.berkeley.edu/courses/EEP118/current/derive_ols.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the coefficients\n",
    " \n",
    "* $\\hat{b}_0$: the value of the response when the predictor is equal to 0\n",
    "    - The estimated mean of y, the dependent variable\n",
    "* $\\hat{b}_1$: the amount (in $\\hat{b}_1$ units) that the mean response will increase or decrease by for every one unit increase in x.\n",
    "\n",
    "#### What to $\\hat{b}_0$ and $\\hat{b}_1$ estimate?\n",
    "\n",
    "* Population Mean\n",
    "* Will get a different estimate with a different sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions of Least Squares\n",
    " \n",
    "* **Linear** relationship between response and predictor variables\n",
    "* Error terms are **Independent**\n",
    "* The error term is **Normally distributed** $N(0,\\sigma^2)$\n",
    "* Homoscedastic: **Equal** variance of the error term\n",
    "* Under these assumptions, the Method of Least Squares is the Maximum Likelihood Estimate (MLE)\n",
    "    - MLE is a probabilistic method (will cover later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residuals(y,yhat):\n",
    "    return y - yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(residuals(y_test,yhat),fit=stats.norm);\n",
    "params = stats.norm.fit(residuals(y_test,yhat))\n",
    "print(f'Mean: {np.round(params[0],3)}, Standard Deviation: {np.round(params[1],3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for Homoscedasticity\n",
    "\n",
    "* Should not be funnel shaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(yhat,residuals(y_test,yhat),'bo')\n",
    "plt.title(\"Fitted vs. Residuals\")\n",
    "plt.xlabel(\"Fitted\")\n",
    "plt.ylabel(\"Residuals\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the accuracy of the model\n",
    "\n",
    " * Goodness of fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  R-squared (coefficient of determination) \n",
    " \n",
    "* Fraction of the total variance in y explained by the predictor(s)\n",
    "* A number between 0 and 1 (i.e. independent of the scale of Y)\n",
    "* $R^2$ close to 1 means a large proportion of the variance in the response is explained by the regression\n",
    "* $R^2$ close to 0 means that not much of the variance is explained: wrong model, inherently high variance or both \n",
    "* Residual Sum of Squares (RSS): squared difference of actual response value and fitted values (i.e. the residuals)\n",
    "* Total Sum of Squares (TSS): squared difference of actual response value and mean response value.\n",
    "\n",
    "<div style=\"font-size: 125%;\"> \n",
    "$$R^2 = \\frac{TSS - RSS}{RSS} = 1 - \\frac{RSS}{TSS}$$\n",
    "$$TSS = \\sum^n_{i=1}(y_i-\\bar{y})^2$$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rss(y,yhat):\n",
    "    return(np.sum(residuals(y,yhat)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tss(y):\n",
    "    return(np.sum((y - np.mean(y))**2))\n",
    "\n",
    "def R_squared(y,yhat):\n",
    "    return(1 - (rss(y,yhat)/tss(y)))\n",
    "\n",
    "R_squared(y_test,yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R-squared from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For a single predictor, R-squared is equal to Pearson's Correlation squared\n",
    "<div style=\"font-size: 125%;\"> \n",
    "$$R^2 = r^2$$\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = stats.pearsonr(X_test[:,0],y_test)[0]\n",
    "r**2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Squared Error\n",
    "\n",
    "* The average of the squared error (i.e. residuals)\n",
    "\n",
    "$$MSE = \\frac{1}{n}\\sum(y - \\hat{y})^2$$\n",
    "\n",
    "* Root Mean Squared Error\n",
    "    - Same unit as response variable\n",
    "\n",
    "$$RMSE = \\sqrt{\\frac{1}{n}\\sum(y - \\hat{y})^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y,yhat):\n",
    "    return np.mean((y - yhat)**2)\n",
    "\n",
    "def rmse(y,yhat):\n",
    "    return np.sqrt(np.mean((y - yhat)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'MSE: {mse(y_test,yhat)}\\nRMSE: {rmse(y_test, yhat)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "1. Change value of random_state in train_test_split\n",
    "\n",
    "2. Change test_size in train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression\n",
    "\n",
    "* The response is a linear function of p predictors\n",
    "\n",
    "<div style=\"font-size: 125%;\">\n",
    "$$Y = \\beta_0 + \\beta_1{X_1} + \\beta_2{X_2} +...+\\beta_p{X_p} + \\epsilon $$\n",
    "</div>\n",
    "\n",
    "* $X_j$ is the jth predictor and $\\beta_j$ is the average effect on Y of a one unit increase in $X_j$ holding all other predictors fixed\n",
    "    \n",
    "* Estimating Regression Coefficients\n",
    "<div style=\"font-size: 125%;\">\n",
    "$$\\hat{y} = \\hat{b}_0 + \\hat{b}_1{x_1} + \\hat{b}_2{x_2} +...+ \\hat{b}_p{x_p}$$\n",
    "</div>\n",
    "Minimize:\n",
    "<div style=\"font-size: 125%;\">\n",
    "$$RSS = \\sum^n_{i=1}(y_i - \\hat{y}_i)^2 = \\sum^n_{i=1}(y_i - \\hat{b}_0 - \\hat{b}_1{x_1} - \\hat{b}_2{x_2} -...- \\hat{b}_p{x_p})^2$$\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Formulation\n",
    "\n",
    "* X is called the Design Matrix (1's in the first column for the intercept and the remaining columns are the predictors)  \n",
    "* $\\beta = (b_0,b_1,...b_n)$\n",
    "* How to find the $\\beta$ that minimizes the RSS? \n",
    "    - Take the partial derivative of RSS with respect to $\\beta$, \n",
    "    - Set it equal to 0\n",
    "    - Solve for $\\beta$\n",
    "* $X\\beta$ is the dot product, $(y-X\\beta)^T(y-X\\beta)$ is the Squared Error\n",
    "\n",
    "<div style=\"font-size: 125%;\">\n",
    "$$RSS(\\beta) = (y-X\\beta)^T(y-X\\beta)$$\n",
    "$$\\frac{\\partial{RSS}}{\\partial{\\beta}} = -2X^T(y-X\\beta)$$\n",
    "$$X^T(y-X\\beta) = 0$$\n",
    "$$X^Ty = X^TX\\beta$$\n",
    "$$\\beta = (X^TX)^{-1}X^Ty$$\n",
    "</div>\n",
    "* Called the Normal Equation, closed form solution to the optimization\n",
    "\n",
    "### Issues with multiple predictors\n",
    "\n",
    "#### Which predictors best explain the response?\n",
    "\n",
    "    \n",
    "#### Is there multicolinearity (i.e. are two or more predictors highly correlated)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(adult,diag_kind='kde');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = adult.loc[:,['weight','age','male']].values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1234)\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train[:,0:2])\n",
    "X_test = scaler.transform(X_test[:,0:2])\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print(f'Intercept: {model.intercept_} Coefficients:: {model.coef_} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test)\n",
    "yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(model.score(X_test,y_test),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(rmse(y_test,yhat),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "1. Create and run a model with just weight and age as predictors. Compare with full model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Linear Regression\n",
    " \n",
    "* Linear model assumes a linear relationship between response and predictors\n",
    "* But what if relationship is non-linear, can we extend model to fit these cases\n",
    "* Polynomial Regression\n",
    "\n",
    "<div style=\"font-size: 115%;\">\n",
    "$$y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\epsilon$$\n",
    "</div>\n",
    "\n",
    "* **This is still a linear model - linear in the coefficients**\n",
    "\n",
    "<div style=\"font-size: 115%;\">\n",
    "$$Z = X^2$$\n",
    "$$y = \\beta_0 + \\beta_1 X + \\beta_2 Z + \\epsilon$$\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "How does height vary with weight for all subjects?\n",
    "\n",
    "* Dependent Variable: height\n",
    "* Independent Varible: weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = howell.weight.values.reshape(-1,1)\n",
    "y = howell.height.values\n",
    "\n",
    "plt.scatter(X, y, color = 'red')\n",
    "plt.title(f'{ylabel} vs. {xlabel} all ages')\n",
    "plt.xlabel(xlabel)\n",
    "plt.ylabel(ylabel);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1234)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test)\n",
    "yhat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Intercept: {model.intercept_} Coefficients: {model.coef_} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'R-squared: {np.round(model.score(X,y),2)}')\n",
    "\n",
    "print(f'RMSE: {np.round(rmse(y_test,yhat),2)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, y, color = 'red')\n",
    "plt.plot(X_test, yhat, color = 'blue')\n",
    "plt.title('Regression Line')\n",
    "plt.xlabel(xlabel)\n",
    "plt.ylabel(ylabel);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try adding a quadratic term\n",
    "\n",
    "<div style=\"font-size: 125%;\">\n",
    "$$ height = \\beta_0 + \\beta_1\\cdot{weight} + \\beta_2\\cdot{weight^2} + \\epsilon$$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "howell['weight2'] = howell.weight**2\n",
    "howell.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = howell.loc[:,['weight','weight2']].values\n",
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X2, y, test_size = 0.2, random_state = 1234)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit quadratic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test)\n",
    "yhat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Intercept: {model.intercept_} Coefficients: {model.coef_} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'R-squared: {np.round(model.score(X2,y),2)}')\n",
    "\n",
    "print(f'RMSE: {np.round(rmse(y_test,yhat),2)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, y, color = 'red')\n",
    "plt.plot(X_test[:,0], yhat, 'bo')\n",
    "plt.title('Predicted Values')\n",
    "plt.xlabel(xlabel)\n",
    "plt.ylabel(ylabel);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "1. Add cubic term to model and compare with quadratic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "936px",
    "right": "20px",
    "top": "96px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
