{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports for AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting\n",
    "\n",
    " \n",
    "* A general approach that can be applied to many statistical learning methods for regression or classification. \n",
    "* Not a learning method, it boosts performance of other learning methods such as decision trees, linear regression, etc.\n",
    "* An ensemble method, it sequentially combines base learners to improve performance\n",
    "* Not prone to overfitting\n",
    "    - Empirical result\n",
    "    - Can overfit but not as much as other methods\n",
    "* Boosting is a method of combining a sequence of **Weak Learners** $h_i$ into a strong learner H\n",
    "    - Each weak learner gets a vote in determining the final result\n",
    "    \n",
    "<div style=\"font-size: 110%;\">\n",
    "$$H(x) = sign(\\alpha_1h_1(x) + \\alpha_2h_2(x) + ... + \\alpha_nh_n(x))$$\n",
    "</div>\n",
    "\n",
    "* H(x) is the final ensemble learner\n",
    "* $h_i(x)$ is a weak learner\n",
    "* $\\alpha_i$ is the voting power of weak learner $h_i$\n",
    "\n",
    "![](MisClassArea1.png)\n",
    "$$\\text{Figure 1. Weak Learners. Shaded area is the area where the learner misclassifies the samples}$$\n",
    "\n",
    "#### Weak Learner\n",
    " \n",
    "* A learning algorithm that performs slightly better than chance\n",
    "    - e.g. a tree with one split, called a stump\n",
    "* Each weak learner misclassifies samples in part of the space (see Figure 1)\n",
    "\n",
    "#### Error rate\n",
    "\n",
    "![](ErrorRate.png)\n",
    "$$\\text{Figure 2. Error Rates for Learners}$$\n",
    "\n",
    "#### Emphasize data points that have been misclassified.\n",
    "\n",
    "* In each iteration focus on data points that were misclassified in the previous round\n",
    "    - Weighting\n",
    "    - Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different Types of Boosting Algorithm\n",
    "\n",
    "* Adaptive Boosting (AdaBoost, Freund and Schapire (1997))\n",
    "    - sklearn\n",
    "* Gradient Boosting\n",
    "    - sklearn\n",
    "    - XGBoost (2014)\n",
    "    - Catboost (2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADABoost (Adaptive Boosting)\n",
    "\n",
    "* Freund and Schapire (1996)\n",
    "    - Godel Prize (2003)\n",
    "    \n",
    "* Any machine learner that accepts weights on training data can be used as the base learner  \n",
    "* Most often applied to Trees  \n",
    "* The samples that the previous tree performed the worst on are given extra weight\n",
    "    - Easy to implement since weights just need to be scaled from one iteration to the next\n",
    "    - For regression: the samples that had the highest mean squared error\n",
    "    - For classification: the samples that were misclassified \n",
    "* Often can just use tree stumps (i.e. trees with only one split)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Illustration\n",
    "\n",
    "![](TreeStumps.png)\n",
    "$$\\text{Figure 3. Ensemble of 3 Tree Stumps}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Problem\n",
    "\n",
    "![](Example.png)\n",
    "$$\\text{Figure 4. Example Problem}$$\n",
    "\n",
    "#### Data Points:\n",
    "\n",
    "A,B,C,D,E will be assigned weights $w_i$\n",
    "\n",
    "#### Weak Learners : Tree stumps\n",
    "\n",
    "Classify samples to the left as positive and to the right as negative: x < 2, x < 4, x < 6  \n",
    "\n",
    "Classify samples to the right as positive and to the left as negative: x > 2, x > 4, x > 6  \n",
    "\n",
    "#### Trying to construct ensemble\n",
    "\n",
    "<div style=\"font-size: 110%;\">\n",
    "$$H(x) = sign(\\alpha_1h_1(x) + \\alpha_2h_2(x) + ... + \\alpha_nh_n(x))$$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm\n",
    "\n",
    "* Iterative algorithm to find the best weak learner based on lowest error rate at each iteration and add it to the ensemble multiplied by its voting power.\n",
    "* Error Rate is sum of the weights assigned to misclassified samples\n",
    "* These weights are a distribution, i.e. they must add to 1.\n",
    "* For correctly classified samples the weights will decrease and for incorrectly classified samples the weight will increase\n",
    "\n",
    "![](ADABoostAlgo1.png)\n",
    "$$\\text{Figure 4. ADABoost Algorithm Flow Chart}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_idx(id):\n",
    "    return ('A','B','C','D','E').index(id)\n",
    "\n",
    "class WeakLearner():\n",
    "    def __init__(self,i,fn):\n",
    "        self.f = fn\n",
    "        self.name = f'f{i+1}'\n",
    "        self.miss_class_label_ = []\n",
    "        self.miss_class = []\n",
    "        self.alpha_ = 0\n",
    "        self.error_rate_ = 0\n",
    "        \n",
    "    def calc_miss_classifications(self,data):\n",
    "        for d in data:\n",
    "            if self.f(d) == -1: \n",
    "                self.miss_class_label_.append(d.id)\n",
    "                self.miss_class.append(id_idx(d.id))\n",
    "                \n",
    "    def calc_error_rate(self,w):\n",
    "        self.error_rate_ = np.sum(w[self.miss_class])\n",
    "    \n",
    "    def calc_voting_power(self):\n",
    "        self.alpha_ = 1/2*np.log((1 - self.error_rate_) / self.error_rate_)\n",
    "        \n",
    "Weak_Learners = [WeakLearner(i,f) for i,f in enumerate(\n",
    "                    [lambda d: 1 if (d.x < 2) == d.clss else -1,\n",
    "                     lambda d: 1 if (d.x < 4) == d.clss else -1,\n",
    "                     lambda d: 1 if (d.x < 6) == d.clss else -1,\n",
    "                     lambda d: 1 if (d.x > 2) == d.clss else -1,\n",
    "                     lambda d: 1 if (d.x > 4) == d.clss else -1,\n",
    "                     lambda d: 1 if (d.x > 6) == d.clss else -1])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPoint():\n",
    "    def __init__(self,vals):\n",
    "        self.id = vals[0]\n",
    "        self.x = vals[1]\n",
    "        self.clss = 1 if vals[2] == '+' else 0\n",
    "        self.weight_ = None\n",
    "        \n",
    "    def update_weight(self,best):\n",
    "        if self.id not in best.miss_class_label_:\n",
    "            self.weight_ = 1/2*(1/(1 - best.error_rate_))*self.weight_\n",
    "        else:\n",
    "            self.weight_ = 1/2*(1/best.error_rate_)*self.weight_\n",
    "\n",
    "Data = [DataPoint(v) for v in [('A',1,'+'),\n",
    "                               ('B',5,'+'),\n",
    "                               ('C',3,'-'),\n",
    "                               ('D',1,'+'),\n",
    "                               ('E',5,'+')]]   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting: returns +1 or -1\n",
    "def eval_H(d,H):\n",
    "    return np.sign(np.sum([h.alpha_*h.f(d) for h in H]))\n",
    "\n",
    "H = []  # List of the best Weak Learner at each iteration\n",
    " \n",
    "def H_accuracy(H,data):\n",
    "    tot = len(data)\n",
    "    c = 0\n",
    "    for d in data:\n",
    "        c += eval_H(d,H)\n",
    "    return c/tot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Miss Classification for each learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learner f1: ['B', 'E']\n",
      "Learner f2: ['B', 'C', 'E']\n",
      "Learner f3: ['C']\n",
      "Learner f4: ['A', 'C', 'D']\n",
      "Learner f5: ['A', 'D']\n",
      "Learner f6: ['A', 'B', 'D', 'E']\n"
     ]
    }
   ],
   "source": [
    "# Test of calculating miss classifications\n",
    "for wl in Weak_Learners:\n",
    "    wl.calc_miss_classifications(Data)\n",
    "    print(f'Learner {wl.name}: {wl.miss_class_label_}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(Data)\n",
    "for d in Data:\n",
    "    d.weight_ = 1/N\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop Control and max number of iterations\n",
    "max_round = 4\n",
    "round = 1\n",
    "done = False\n",
    "\n",
    "# Iterate until a stopping criteria is met\n",
    "#while not done:\n",
    "def one_round(round):\n",
    "\n",
    "    weights = np.array([d.weight_ for d in Data])\n",
    "    \n",
    "    print(f'Round {round} \\n Weights {np.round(weights,3)}')\n",
    "    \n",
    "    # Calculate Error Rate\n",
    "    for wl in Weak_Learners:\n",
    "        wl.calc_error_rate(weights)\n",
    "        \n",
    "    print(f'Error Rates: {[np.round(wl.error_rate_,3) for wl in Weak_Learners]}')\n",
    "       \n",
    "    # Determine Best weak learner (one with smallest error rate), if ties 1st one will be the best\n",
    "    best = Weak_Learners[0]\n",
    "    for wl in Weak_Learners[1:]:\n",
    "        if wl.error_rate_ < best.error_rate_:\n",
    "            best = wl\n",
    "            \n",
    "    # Calculate alpha for best learner        \n",
    "    best.calc_voting_power()\n",
    "    \n",
    "    # Add best to ensemble H\n",
    "    H.append(best)\n",
    "    \n",
    "    print(f'Best: {best.name}, Error Rate: {np.round(best.error_rate_,3)}, Alpha: {np.round(best.alpha_,3)}')   \n",
    "    \n",
    "    # Update all the weights\n",
    "    for d in Data:\n",
    "        d.update_weight(best)\n",
    "        \n",
    "    # Calculate Accuracy of current ensemble\n",
    "    accuracy = H_accuracy(H,Data)\n",
    "    print(f'Accuracy of Ensemble: {accuracy}')\n",
    "  \n",
    "    # Check atopping conditions\n",
    "    round += 1\n",
    "    if round == max_round or best.error_rate_ == 0.5 or accuracy == 1:\n",
    "        done = True\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931471805599453"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test of one_round, expected result\n",
    "Best = 'f3'\n",
    "Error_rate = 0.2\n",
    "alpha = .5*np.log(4)\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 \n",
      " Weights [0.2 0.2 0.2 0.2 0.2]\n",
      "Error Rates: [0.4, 0.6, 0.2, 0.6, 0.4, 0.8]\n",
      "Best: f3, Error Rate: 0.2, Alpha: 0.693\n",
      "Accuracy of Ensemble: 0.6\n"
     ]
    }
   ],
   "source": [
    "one_round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 2 \n",
      " Weights [0.125 0.125 0.5   0.125 0.125]\n",
      "Error Rates: [0.25, 0.75, 0.5, 0.75, 0.25, 0.5]\n",
      "Best: f1, Error Rate: 0.25, Alpha: 0.549\n",
      "Accuracy of Ensemble: 0.6\n"
     ]
    }
   ],
   "source": [
    "one_round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 3 \n",
      " Weights [0.083 0.25  0.333 0.083 0.25 ]\n",
      "Error Rates: [0.5, 0.833, 0.333, 0.5, 0.167, 0.667]\n",
      "Best: f5, Error Rate: 0.167, Alpha: 0.805\n",
      "Accuracy of Ensemble: 1.0\n"
     ]
    }
   ],
   "source": [
    "one_round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.WeakLearner at 0x7fc07cc032b0>,\n",
       " <__main__.WeakLearner at 0x7fc07cc03198>,\n",
       " <__main__.WeakLearner at 0x7fc07cc03390>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6931471805599453, 0.5493061443340549, 0.8047189562170503)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H[0].alpha_,H[1].alpha_,H[2].alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of Mathematical Derivation\n",
    "\n",
    "#### Ensemble that classifies the data\n",
    "\n",
    "<div style=\"font-size: 115%;\">\n",
    "$$H(x) = sign(\\alpha_1h_1(x) + \\alpha_2h_2(x) + ... + \\alpha_nh_n(x))$$\n",
    "</div>\n",
    "\n",
    "#### Weight Update\n",
    "\n",
    "Suppose the weight at time t+1 is:\n",
    "\n",
    "<div style=\"font-size: 115%;\">\n",
    "$$w^{t+1_i} = \\frac{w^t_i}{Z}exp(-\\alpha^th^t(x)y(x))$$\n",
    "</div>\n",
    "  \n",
    "y(x) = 1 if weight is for a positive sample, and -1 for a negative sample  \n",
    "Weights must add to 1, Z is a normalizing constant  \n",
    "\n",
    "#### To minimize the error of H(x)\n",
    "\n",
    "Freund and Schapire derived:  \n",
    "\n",
    "A minimum error bound for H(x)\n",
    "\n",
    "<div style=\"font-size: 115%;\">\n",
    "$$\\alpha^t = \\frac{1}{2}log\\frac{1-\\epsilon^t}{\\epsilon^t}$$\n",
    "</div>\n",
    "\n",
    "* $\\epsilon$ is the error rate\n",
    "* The error can go up as terms are added to H but is bounded by the\n",
    "decaying exponential\n",
    "\n",
    "#### Substitute $\\alpha$ into weight update:\n",
    "If Correct:  \n",
    "<div style=\"font-size: 115%;\">\n",
    "$$w^{t+1_i} = \\frac{w^t_i}{Z}* \\sqrt{\\frac{\\epsilon^t}{1 - \\epsilon^t}} $$\n",
    "</div> \n",
    "If Incorrect:  \n",
    "\n",
    "<div style=\"font-size: 115%;\">\n",
    "$$w^{t+1_i} = \\frac{w^t_i}{Z}* \\sqrt{\\frac{1 - \\epsilon^t}{\\epsilon^t}}$$\n",
    "</div>\n",
    "  \n",
    "Z is the normalizing constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weights must add to 1, so add the correct and incorrect weights without the Z to calculate Z . \n",
    "\n",
    "<div style=\"font-size: 115%;\">\n",
    "$$Z =  \\sqrt{\\frac{\\epsilon^t}{1 - \\epsilon^t}}*\\sum_{Correct}w^t + \\sqrt{\\frac{1 - \\epsilon^t}{\\epsilon^t}}*\\sum_{Incorrect}w^t$$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since $\\sum_{Incorrect}w^t = \\epsilon^t$ and $\\sum_{Correct}w^t = 1 - \\epsilon^t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size: 115%;\">\n",
    "$$Z =  \\sqrt{\\epsilon^t(1 - \\epsilon^t)} + \\sqrt{\\epsilon^t(1 - \\epsilon^t)} = 2\\sqrt{\\epsilon^t(1 - \\epsilon^t)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight Update Equations\n",
    "\n",
    "<div style=\"font-size: 115%;\">\n",
    "$$ w^{t+1_i} = \\frac{w^t_i}{2}\\frac{1}{1 - \\epsilon} \\text{ }\\text{ if Correct}$$\n",
    "$$ w^{t+1_i} = \\frac{w^t_i}{2}\\frac{1}{\\epsilon} \\text{ }\\text{ if Incorrect}$$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add up Correct\n",
    "\n",
    "<div style=\"font-size: 115%;\">\n",
    "$$\\frac{1}{2}\\frac{1}{1 - \\epsilon^t}\\sum_{Correct}w^t = \\frac{1}{2}\\frac{1 - \\epsilon^t}{1 - \\epsilon^t} = \\frac{1}{2}$$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thus\n",
    "\n",
    "<div style=\"font-size: 115%;\">\n",
    "$$\\sum_{Correct}w^{t+1_i} = \\frac{1}{2} = \\sum_{Incorrect}w^{t+1_i}$$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADABoost in sklearn\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
    "\n",
    "#### Parameters\n",
    "\n",
    "* base estimator: Default: DecisionTreeClassifier(max_depth = 1)\n",
    "* n_estimators: number of estimators\n",
    "* learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = sns.load_dataset('iris')\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.iloc[:,0:4].values\n",
    "y = iris.iloc[:,4].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0,stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AdaBoostClassifier(n_estimators=100,learning_rate = 1.0)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal_length 0.0\n",
      "sepal_width 0.01\n",
      "petal_length 0.5\n",
      "petal_width 0.49\n"
     ]
    }
   ],
   "source": [
    "for n,v in zip(iris.columns.tolist()[0:-1],model.feature_importances_):\n",
    "    print(n,v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  2 10]]\n",
      "Accuracy is:  0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, yhat)\n",
    "print(cm)\n",
    "accuracy = np.trace(cm)/np.sum(cm)\n",
    "print(\"Accuracy is: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8648221343873518"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AdaBoostClassifier(n_estimators=100,learning_rate = 1.0)\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "scores.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1,6),scores);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADABoost Regression\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html#sklearn.ensemble.AdaBoostRegressor\n",
    "#### Parameters\n",
    "\n",
    "* base estimator: Default: DecisionTreeRegressor(max_depth = 3)\n",
    "* n_estimators: number of estimators\n",
    "* learning_rate\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/ensemble/plot_adaboost_regression.html#sphx-glr-auto-examples-ensemble-plot-adaboost-regression-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Boston = pd.read_csv(\"Boston.csv\")\n",
    "X = Boston.iloc[:, 0:13].values\n",
    "y = Boston.iloc[:, 13].values\n",
    "feats = Boston.columns.tolist()[0:13]\n",
    "\n",
    "# Validation Set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare Decision Tree with ADABoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.075 R2: 0.677\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor(random_state = 12)\n",
    "dt.fit(X_train,y_train)\n",
    "yhat = dt.predict(X_test)\n",
    "mse = np.mean(y_test - yhat)**2\n",
    "print(f'MSE: {np.round(mse,3)} R2: {np.round(dt.score(X_test,y_test),3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(random_state=12),\n",
       "                  n_estimators=500, random_state=42)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_regress = AdaBoostRegressor(dt,n_estimators = 500,\n",
    "                                learning_rate = 1.0,\n",
    "                                random_state = 42)\n",
    "ada_regress.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.249 R2: 0.832\n"
     ]
    }
   ],
   "source": [
    "yhat = ada_regress.predict(X_test)\n",
    "mse = np.mean(y_test - yhat)**2\n",
    "print(f'MSE: {np.round(mse,3)} R2: {np.round(ada_regress.score(X_test,y_test),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Linear Regression as an estimator rather than Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.35 R2: 0.785\n"
     ]
    }
   ],
   "source": [
    "ada_regress = AdaBoostRegressor(n_estimators = 700,\n",
    "                                learning_rate = 1.0,\n",
    "                                random_state = 4)\n",
    "ada_regress.fit(X_train,y_train)\n",
    "yhat = ada_regress.predict(X_test)\n",
    "mse = np.mean(y_test - yhat)**2\n",
    "print(f'MSE: {np.round(mse,3)} R2: {np.round(ada_regress.score(X_test,y_test),3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.095 R2: 0.684\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "yhat = lr.predict(X_test)\n",
    "mse = np.mean(y_test - yhat)**2\n",
    "print(f'MSE: {np.round(mse,3)} R2: {np.round(lr.score(X_test,y_test),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "Patrick Winston: Learning Boosting, https://www.youtube.com/watch?v=UHBmv7qCey4&t=1636s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
