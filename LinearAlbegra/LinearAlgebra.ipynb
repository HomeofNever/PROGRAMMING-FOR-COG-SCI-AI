{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.linalg as la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Algebra\n",
    "\n",
    "https://docs.scipy.org/doc/numpy-1.13.0/reference/routines.linalg.html\n",
    "\n",
    "* Vectors\n",
    "    * Norm\n",
    "    * Dot Product\n",
    "    * Similarity\n",
    "    * Projection\n",
    "    * Linear Independence\n",
    "    \n",
    "* Matricies\n",
    "    * Operations\n",
    "    * System of linear equations\n",
    "    * Eigenvalues eigenvectors\n",
    "    * Matrix Decomposition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectors\n",
    "\n",
    "* **Definition** A vector is an object that has a magnitude and a direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Magnitude of a vector \n",
    "\n",
    "* Length of a vector v = $(v_1,v_2,...,v_n)$ is called its **norm**\n",
    " \n",
    " <div style=\"font-size: 115%;\">\n",
    "$$ ||v|| = \\sqrt{\\sum_{i=1}^{n}v_i^2}$$\n",
    "</div>\n",
    "\n",
    "* Often referred to as the L2 Norm, $||v||_2$\n",
    "\n",
    "#### Unit Vector\n",
    "* Denote the unit vector for a vector v by $\\hat{v}$\n",
    "\n",
    "<div style=\"font-size: 115%;\">\n",
    "$$ \\hat{v} = \\frac{v}{||v||}$$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Norm(v):\n",
    "    return np.sqrt(np.sum(v**2))\n",
    "v = np.array([1,2,3,4,5])\n",
    "Norm_v = Norm(v)\n",
    "Unit_v = v/Norm_v\n",
    "print(f'Norm v : {Norm_v} \\nUnit v: {Unit_v}\\nNorm Unit v: {Norm(Unit_v)}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direction of a vector\n",
    "\n",
    "Given a vector $v = (v_1,v_2,...,v_n)$, the direction of $v$ is the vector $(\\frac{v_1}{||v||},\\frac{v_2}{||v||},...,\\frac{v_n}{||v||})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unit_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dot product \n",
    "\n",
    "* Multiply vectors to get a scalar\n",
    "\n",
    "<div style=\"font-size: 115%;\">\n",
    "$$  v = (v_1,v_2,...,v_n), w = (w_1,w_2,...,w_n)$$\n",
    "</div>    \n",
    "\n",
    "#### Algebraic Definition\n",
    "\n",
    "<div style=\"font-size: 115%;\">\n",
    "$$  v\\centerdot{ w} = \\sum_i^n v_i*w_i $$\n",
    "</div>\n",
    "\n",
    "#### Geometric Definition\n",
    "\n",
    "<div style=\"font-size: 115%;\">\n",
    "$$  v\\centerdot{ w} = cos(\\theta)\\Vert v \\Vert \\Vert w\\Vert$$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.array([1,2,3,4,5])\n",
    "w = np.array([2,4,6,8,10])\n",
    "np.vdot(v,w),v.dot(w),w.dot(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.array([2,2])\n",
    "w = np.array([2,0])\n",
    "np.vdot(v,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "round(math.cos(math.radians(45)) * la.norm(v) * la.norm(w),10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuresof similarity of two vectors\n",
    "\n",
    "* Support Vector Machines \n",
    "* NLP: semantic similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.array([1,1,1,1])\n",
    "\n",
    "w = np.array([2,2,2,2])\n",
    "np.dot(v,w)/(la.norm(v)*la.norm(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Orthogonal (perpendicular) vectors\n",
    " \n",
    "* $a\\cdot{b} = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array((1,1))\n",
    "b= np.array((-1,1))\n",
    "adotb = np.vdot(a,b)\n",
    "adotb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projection\n",
    "\n",
    "![](proj.png)\n",
    "\n",
    "#### Vector Projection of x onto y\n",
    "\n",
    "<div style=\"font-size: 115%;\">\n",
    "$$ proj_y x = \\frac{x\\cdot{y}}{||y||^2}y$$\n",
    "</div>\n",
    "\n",
    "#### Scalar Projection of x onto y\n",
    "\n",
    "* The length of the projection\n",
    "\n",
    "<div style=\"font-size: 115%;\">\n",
    "$$ proj_y x = \\frac{x\\cdot{y}}{||y||}$$\n",
    "</div>\n",
    "\n",
    "* **$x\\cdot{y}$ is the length of the projection of x onto the unit vector $\\hat{y}$** ( $\\frac{y}{||y||}$ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([3,0])\n",
    "x = np.array([2,1])\n",
    "unit_y = y/Norm(y)\n",
    "np.vdot(x,y)/Norm(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.arcsin(1/Norm(x))\n",
    "Norm(x)*np.cos(theta)                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Independence\n",
    "\n",
    "* A set of  vectors, $(v_1,v_2...v_n)$ are linearly dependent if one of the vectors can be expressed as a linear combination of the others.\n",
    "    - At least two of the vectors lie on the same line (they differ in magnitude only)\n",
    "\n",
    "* Vectors that are not linearly dependent are linearly independent.\n",
    "* A set of vectors are linearly independent if:\n",
    "<div style=\"font-size: 115%;\"> \n",
    "$$ a_1 v_1 + a_2 v_2 + ...+ a_n v_n = 0 \\text{ iff all } a_i = 0$$\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not linear independent since 2v-1w = 0, \n",
    "v = np.array([1,2,3,4])\n",
    "w = np.array([2,4,6,8])\n",
    "\n",
    "np.sum(2*v + (-1*w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.array([1,2,3,4])\n",
    "w = np.array([3,5,7,9])\n",
    "np.sum(2*v + (-1*(w - 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'cosine of angle between the vectors: {np.round(np.dot(v,w)/(la.norm(v)*la.norm(w)),2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matricies\n",
    "\n",
    "\n",
    "### Matrix Multiplication Operations\n",
    "\n",
    "#### Matrix Multiplication\n",
    "\n",
    "* Must be compatible: number of columns of 1st matrix = number of rows of second matrix\n",
    "* Result: number of rows of 1st matrix and number of columns of 2nd \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy matmul\n",
    "A = np.array([1,2,3,4,5,6,7,8]).reshape(4,2)\n",
    "B = np.array([1,2,3,4,5,6]).reshape(2,3)\n",
    "# 4x2 * 2x3 = 4x3\n",
    "M = np.matmul(A,B)\n",
    "print(\"Shape: \", M.shape)\n",
    "print(\"M\\n\",M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy dot product\n",
    "np.dot(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pure Python\n",
    "print(A@B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix by a scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(A,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hadamard Product\n",
    "\n",
    "* Element by element multiplication\n",
    "\n",
    "* Often denoted as $A \\circ B$\n",
    "\n",
    "* In python, it is the * operator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array( [[1,1],[0,1]] )\n",
    "B = np.array( [[2,0],[3,4]] )\n",
    "\n",
    "print(\"A\\n\",A)\n",
    "print(\"B\\n\",B)\n",
    "M = A*B # Hadamard\n",
    "print(\"Shape of A*B: \", M.shape)\n",
    "print(\"M\\n\", M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Matrices must have same shape or can broadcast one into the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.array([5]*8).reshape(4,2)\n",
    "A*C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.array([[5],[6]]).reshape(2,1)\n",
    "print(\"A\\n\",A)\n",
    "print(\"D\\n\",D)\n",
    "print(A.shape,D.shape)\n",
    "print(A*D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix times a vector\n",
    "\n",
    "* Matrix as a transformation operator on a vector\n",
    "    - Changes orientation and length of a vector (rotates and stretches or shrinks a vector\n",
    "* np.matmul or np.dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A= np.arange(10).reshape(5,2)\n",
    "v = np.array([11,12])\n",
    "print(\"A\\n\",A)\n",
    "print(\"v\\n\",v)\n",
    "b = A.dot(v)\n",
    "print(\"b\\n\",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.matmul(A,v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagonal and Trace\n",
    "\n",
    "* Diagonal: $a_{ij}$ where i=j elements\n",
    "* trace: sum of diagonal elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([1,2,3])\n",
    "np.diag(A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.eye(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "print(\"A\\n\",A)\n",
    "print(f'Trace of A: {np.trace(A)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1,2,3],[4,5,6]])\n",
    "print(\"A\\n\",A)\n",
    "print(\"A-transpose\\n\",A.transpose())\n",
    "print(\"<AA-transpose>\\n\",np.dot(A,A.transpose())) #Notice its a square matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determinant\n",
    " \n",
    "* Only for square matrices\n",
    "* For 2x2 matrix $\\begin{bmatrix}a & b \\\\ c & d\\end{bmatrix}$, det = ad-bc \n",
    "* If non-zero, then matrix has an inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.arange(4).reshape(2,2)\n",
    "la.det(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Matrix Inversion ($A^{-1}$)\n",
    "\n",
    "$$ AA^{-1} = I$$\n",
    "\n",
    "#### Must be a square matrix\n",
    "\n",
    "* To be invertible, A must have non-zero determinant\n",
    "    - If det(A) = 0 then A is called a singular matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.arange(9).reshape(3,3)\n",
    "A[0,0] = 1\n",
    "A[2,2] = 1\n",
    "print(\"A\\n\",A)\n",
    "B = la.inv(A)\n",
    "print(\"A Inverse\\n\",B)\n",
    "print(\"AA-inverse\\n\",np.round(np.matmul(A,B)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1,3],[2,6]])\n",
    "la.inv(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moore-Penrose Inverse (for real-valued matrices)\n",
    "\n",
    "* For any mxn matrix (not necessarily square) A that has full rank (i.e. independent rows or columns)\n",
    "* If columns of A are linearly independent then:\n",
    "$$ A^+ = (A^TA)^{-1}A^T$$\n",
    "$$\\text{Left Inverse } A^+A = I$$\n",
    "* If the rows of A are linearly independent:\n",
    "$$ A^+ = A^T(AA^T)^{-1}$$\n",
    "$$\\text{Right Inverse } AA^+ = I$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1,2,3,4],\n",
    "              [5,7,9,10]]).reshape(4,2)\n",
    "\n",
    "print(\"Linearly independent columns\\n\",A)\n",
    "\n",
    "AT_A = np.matmul(A.T,A)\n",
    "A_plus = np.matmul(la.inv(AT_A),A.T)\n",
    "print(f'A+\\n{A_plus}')\n",
    "I = np.matmul(A_plus,A).round(2)\n",
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_plus = la.pinv(A)\n",
    "I = np.matmul(A_plus,A)\n",
    "\n",
    "print(f'Left inverse: {A_plus}\\nI = {I.round(4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear operations on vectors (in a vector space)\n",
    " \n",
    "* Matrices are linear operators acting on column vectors\n",
    "       \n",
    "#### Linear system of equations\n",
    "<div style=\"font-size: 115%;\"> \n",
    "$$  Ax = b$$\n",
    "</div>\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    1 & 2 & 3 \\\\\n",
    "    4 & 5 & 6 \\\\\n",
    "    7 & 8 & 9\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix} 21 \\\\ 32 \\\\ 43\\end{bmatrix}\n",
    "$$\n",
    "  \n",
    "* To solve $x = A^{-1}b$ you must find $A^{-1}$ \n",
    "* Finding the inverse means solving $AA^{-1} = I$\n",
    "* This is inefficient (and can induce numerical error) because you still had to solve a linear system of equations\n",
    "* More efficient algorithms use matrix decomposition such as LU decomposition\n",
    "    - Decomposes A into an Upper Triangular (U) and a Lower Triangular Matrix (L)\n",
    "    - Solves L(U(x)) = b\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array((2,4,3,6,16,10,4,12,9)).reshape(3,3)\n",
    "b = np.array((21,32,43))\n",
    "x = la.solve(A,b)\n",
    "print(\"Solution\\n\",x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenvalues and Eigenvectors\n",
    "\n",
    "<div style=\"font-size: 115%;\">\n",
    "$$Ax =  \\lambda x$$\n",
    "</div>\n",
    "\n",
    "* $\\lambda$ is an eigenvalue, x is an eigenvector\n",
    "* The eigenvectors of an linear operator(matrix) are those vectors that don't change direction under the linear transformation.    \n",
    "* They stretch (or shrink) by the amount indicated by the eigenvalue.  \n",
    "* nxn matrices only   \n",
    "* A nxn matrix will have n eigenvectors  \n",
    "* Sum of eigenvalues = trace of A, \n",
    "* Product of eigenvalues = det(A) \n",
    "*   Many uses of eigenvalues/eigenvectors in statistics, machine learning, etc\n",
    "    - Principal Component Analysis\n",
    "    \n",
    "#### To find all n eigenvalues and eigenvectors solve:\n",
    " <div style=\"font-size: 115%;\">   \n",
    "$$(A - \\lambda I)x = 0$$ \n",
    "</div>\n",
    "\n",
    "* $\\lambda$ is the vector of eigenvalues\n",
    "* x is the matrix of eigenvectors (i.e. the columns of x)\n",
    "\n",
    "* numpy linear algebra module has function eig\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([i for i in range(9)]).reshape(3,3)\n",
    "print(\"A\\n\",A)\n",
    "E = la.eig(A)\n",
    "\n",
    "# Eigenvalues\n",
    "print(\"The eigenvalues are: \", np.round(E[0],5))\n",
    "\n",
    "# Eigenvectors\n",
    "\n",
    "print(\"The eigenvecors are: \\n\" , np.round(E[1],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e,v = la.eig(A)\n",
    "print(\"Eigenvalues\\n\",e)\n",
    "print(\"Eigenvectors\\n\",v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(E[0])):\n",
    "    print(f\"Eigenvalue {i+1}: {E[0][i]}, Eigenvector: {E[1][:,i]} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Positive Definite Matrices\n",
    "* Symmetric\n",
    "* A matrix is a positive definite matrix its eigenvalues are all > 0\n",
    "    - $\\ge0$ for semi-definite\n",
    "* A positive definite matrix guarantees that:\n",
    "\n",
    "<div style=\"font-size: 115%;\"> \n",
    "$$x^tAx > 0 \\text{ for all non-zero x} \\in R^n $$\n",
    "</div>\n",
    "* A positive semi-definite matrix guarantees:\n",
    "\n",
    "<div style=\"font-size: 115%;\"> \n",
    "$$x^tAx \\ge 0 \\text{ for all non-zero x} \\in R^n $$  \n",
    "</div>\n",
    "\n",
    "* For 2x2 matrix, \n",
    "$\\begin{bmatrix}a & b \\\\b & c\\end{bmatrix}\\text{ Positive Definite if } ac-b^2 > 0 \\text{ for a > 0}$\n",
    " \n",
    "* Generalization of positive real numbers to matricies\n",
    "    - Positive time a positive is positive\n",
    "    - Can take square roots\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigendecomposition\n",
    "\n",
    "* If an n×n matrix A has n linearly independent eigenvectors, then A may be decomposed as follows:\n",
    "\n",
    "<div style=\"font-size: 115%;\"> \n",
    "$$A = B \\Lambda B^{-1}$$\n",
    "</div>\n",
    "\n",
    "$\\Lambda$ is a diagonal matrix of the eigenvalues\n",
    "B is a matrix whose columns are the independent eigenvectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[0,1,1],[2,1,0],[3,4,5]])\n",
    "print(\"A\\n\",A)\n",
    "u, V = la.eig(A)\n",
    "print(f'B\\n {V}\\nLAMBDA\\n {np.diag(u)}\\nB-inverse\\n {la.inv(V)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $B \\Lambda B^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.dot(V,np.dot(np.diag(u), la.inv(V))).round(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Singular Value Decomposition\n",
    "$$A = UDV^t$$\n",
    "\n",
    "* Where U and V are orthogonal, i.e. \n",
    "      \n",
    "$$U^{-1}=U^t$$ \n",
    "\n",
    "$$V^{-1} = V^t$$\n",
    "\n",
    "* D is a diagonal matrix, the singular values of A\n",
    "* Used in Latent Semantic Analysis, Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array((1,1/2,1/3,1/2,1/3,1/4,1/3,1/4,1/5)).reshape(3,3)\n",
    "print(\"X\\n\",X)\n",
    "S = la.svd(X)\n",
    "print(\"U: \\n\", np.round(S[0],3))\n",
    "print(\"D: \\n\", np.round(S[1],3))\n",
    "print(\"V-transpose: \\n\", np.round(S[2],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "Show that Linear Regression has a closed form soluition by calculating the Coefficients for the data below using the Normal equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder,StandardScaler,MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "howell = pd.read_csv(\"Howell.csv\",sep=';')\n",
    "\n",
    "\n",
    "adult = howell.query(\"age > 17\")\n",
    "adult.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = adult.loc[:,['weight','age']].values\n",
    "y = adult.loc[:,'height'].values\n",
    "\n",
    "model = LinearRegression().fit(X, y)\n",
    "print(f'Intercept: {model.intercept_} \\nCoefficients:: {model.coef_} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show that the sum of the eigenvalues equals the trace of the matrix A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show that the product of the eigenvalues equals the determinant of the matrix A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isclose(np.prod(e) - la.det(A),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
